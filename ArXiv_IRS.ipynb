{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArXiv_IRS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7VYlRZwzGz0P",
        "H96CBWdobell",
        "9gkBzvFBN77G",
        "t3x6rJqXcIN3",
        "w96F2rehmm2Q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosGuzman99/ArXiv_IRS/blob/main/ArXiv_IRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Retrieval System of a subset of physics articles from the arXiv dataset (https://www.kaggle.com/datasets/Cornell-University/arxiv)"
      ],
      "metadata": {
        "id": "qtroYMLr5rm0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXubO_cpCxZw",
        "outputId": "9c6ae29c-4e88-4b6f-cbe6-264f9523a8c3"
      },
      "source": [
        "from google.colab import drive,files\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import statistics\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import json\n",
        "\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYWATY59HA8h"
      },
      "source": [
        "# Def"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getCategories(item_cat, categories):\n",
        "  lst_cat = []\n",
        "  keys = categories.keys()\n",
        "  for cat in keys:\n",
        "    if cat in item_cat:\n",
        "      lst_cat.append(categories[cat])\n",
        "  return lst_cat\n",
        "\n",
        "def print_info(index, itemdata, categories):\n",
        "  item = itemdata[index]\n",
        "  cat = getCategories(item[\"categories\"], categories)\n",
        "  print('Title:', item[\"title\"])\n",
        "  print('Authors:', item[\"authors\"])\n",
        "  print('Categories:', \", \".join(cat))\n",
        "  print('Doi:', item[\"doi\"])\n",
        "  print(item[\"abstract\"])\n",
        "def print_info_lst(index_lst, itemdata, categories):\n",
        "  for index in index_lst:\n",
        "    print('----------------------------------------------')\n",
        "    print_info(index, itemdata, categories)"
      ],
      "metadata": {
        "id": "gJTqlPu7o-Zu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6a4w8-jEb62"
      },
      "source": [
        "#Intersection of two lists\n",
        "def intersection(lst1, lst2):\n",
        "  lst = [val for val in lst1 if val in lst2]\n",
        "  return lst\n",
        "\n",
        "#Union of two lists\n",
        "def union(lst1, lst2):\n",
        "  s1 = set(lst1)\n",
        "  s2 = set(lst2)\n",
        "  lst = list(s1.union(s2))\n",
        "  lst.sort()\n",
        "  return lst\n",
        "\n",
        "#Transpose matrix\n",
        "def traspuesta(matriz):\n",
        "  tr = []\n",
        "  for i in range(len(matriz[0])):\n",
        "    x = [y[i] for y in matriz]\n",
        "    tr.append(x)\n",
        "  return tr\n",
        "\n",
        "def sortDic(dic, rev=False):\n",
        "  new_dic = {}\n",
        "  keys = sorted(dic.keys(), reverse=rev)\n",
        "  for key in keys:\n",
        "    new_dic[key] = dic[key]\n",
        "  return new_dic\n",
        "\n",
        "def sortDicValues(dic, rev=False):\n",
        "  new_dic = {}\n",
        "  values = list(dic.items())\n",
        "  values.sort(key=keySortItem, reverse=rev)\n",
        "  for l,val in values:\n",
        "    new_dic[l] = val\n",
        "  return new_dic\n",
        "\n",
        "def keySortItem(itm):\n",
        "  return itm[1]\n",
        "\n",
        "def graph(x, y, xlab, ylab, n):\n",
        "  plt.subplot(2,1,n)\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel(xlab)\n",
        "  plt.ylabel(ylab)\n",
        "  plt.show\n",
        "\n",
        "#F measure with beta=1 (o alfa=1/2) as default\n",
        "def F_measure(rec_prec, beta=1):\n",
        "  F = {}\n",
        "  b = pow(beta,2)\n",
        "  for p,r in rec_prec.items():\n",
        "    r = 0.5\n",
        "    f = ((b+1)*p*r)/(b*p+r)\n",
        "    F[p*100] = f*100\n",
        "  sortDic(F)\n",
        "  return F\n",
        "\n",
        "def stdIndex(similarity):\n",
        "  std = []\n",
        "  for vector in similarity:\n",
        "    std.append(statistics.pstdev(vector))\n",
        "  aux = sorted(std, reverse=True)\n",
        "  index = []\n",
        "  for val in aux:\n",
        "    ind = std.index(val)\n",
        "    std.pop(ind)\n",
        "    index.append(ind)\n",
        "  return index, aux\n",
        "    \n",
        "def graphDistribution(similarity, doc):\n",
        "  plt.hist(similarity[doc], bins=20)\n",
        "  plt.plot()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VYlRZwzGz0P"
      },
      "source": [
        "## Tokenization, posting list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK587QwuDczg"
      },
      "source": [
        "def remove_d(lst):\n",
        "  data = []\n",
        "  for string in lst:\n",
        "    string = string.replace('Ñ', 'N')\n",
        "    string = string.replace('Ü', 'U')\n",
        "    data.append(''.join([s for s in string if not s.isdigit()]))\n",
        "  return data\n",
        "\n",
        "def tokenize(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  sw = set(stopwords.words('spanish'))\n",
        "  tokens = list(tokenizer.word_index.keys())\n",
        "  aux = []\n",
        "  for token in tokens:\n",
        "    if not token in sw:\n",
        "      aux.append(token)\n",
        "  aux.sort()\n",
        "  tokens_rel = stemming(aux)\n",
        "  tokens_index = tokenIndex(tokens_rel)\n",
        "  return tokens_rel, tokens_index \n",
        "\n",
        "def stemming(tokens):\n",
        "  stemmer = SnowballStemmer('spanish')\n",
        "  tokens_rel = {}\n",
        "  for token in tokens:\n",
        "    word_st = stemmer.stem(token)\n",
        "    if not word_st in tokens_rel.keys():\n",
        "      tokens_rel[word_st] = []\n",
        "    tokens_rel[word_st].append(token)\n",
        "  return tokens_rel\n",
        "\n",
        "def tokenIndex(tokens):\n",
        "  ti = {}\n",
        "  i = 0\n",
        "  for token in tokens:\n",
        "    ti[token] = i\n",
        "    i += 1\n",
        "  return ti\n",
        "\n",
        "#Create posting list\n",
        "def crearPL(tokens_rel, text):\n",
        "  pl = []\n",
        "  for token, words in tokens_rel.items():\n",
        "    aux = []\n",
        "    for word in words:\n",
        "      for i in range(len(text)):\n",
        "        if (word in text[i].lower()) and not (i in aux):\n",
        "          aux.append(i)\n",
        "    pl.append(aux)\n",
        "  return pl\n",
        "\n",
        "#Intersection between the posting list and the query words\n",
        "def intersectionPL(words, pl, ti):\n",
        "  word = ''\n",
        "  while not (word in ti.keys()) and len(words)>0:\n",
        "    word = words.pop(0)\n",
        "  if not word in ti.keys():\n",
        "    return []\n",
        "  i = ti.get(word)\n",
        "  lst = pl[i]\n",
        "  for word in words:\n",
        "    if word in ti.keys():\n",
        "      i = ti[word]\n",
        "      lst = intersection(lst, pl[i])\n",
        "  return lst\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkJhXmNZiwa8"
      },
      "source": [
        "##Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwIjYQNBiyiY"
      },
      "source": [
        "#Query of a string\n",
        "def query(query, pl, ti):\n",
        "  string = query.upper()\n",
        "  string = remove_d([string])\n",
        "  q_tkr, q_tki = tokenize(string)\n",
        "  words = list(q_tkr.keys())\n",
        "  doc = intersectionPL(words, pl, ti)\n",
        "  return doc,q_tkr\n",
        "\n",
        "#Query of a list of strings: query=[string,...]\n",
        "def query_lst(qr, pl, ti):\n",
        "  doc = []\n",
        "  q_tkr = {}\n",
        "  for string in qr:\n",
        "    lst,tkr = query(string, pl, ti)\n",
        "    doc = union(doc, lst)\n",
        "    for token in tkr:\n",
        "      if not token in q_tkr.keys():\n",
        "        q_tkr[token] = tkr[token]\n",
        "        continue\n",
        "      q_tkr[token] = union(q_tkr[token], tkr[token])\n",
        "  return doc, q_tkr\n",
        "\n",
        "#Query weighting\n",
        "def queryWeighting(t_rel, q_tokens, query):\n",
        "  string = ''\n",
        "  if isinstance(query, str):\n",
        "    string = query\n",
        "  else:\n",
        "    for cad in query:\n",
        "      string = string + ' ' + cad\n",
        "  q_tf = []\n",
        "  q_idf = []\n",
        "  q_weighting = [] \n",
        "\n",
        "  l = len(t_rel.keys())\n",
        "  #tf, idf, tf-idf\n",
        "  for i in range(l):\n",
        "    q_tf.append(0)\n",
        "    q_idf.append(0)\n",
        "    token = list(t_rel.keys())[i]\n",
        "    if token in q_tokens.keys():\n",
        "      q_idf[i] = math.log(350,10)\n",
        "      for word in q_tokens[token]:\n",
        "        q_tf[i] += string.count(word)\n",
        "    val = q_tf[i]*q_idf[i]\n",
        "    q_weighting.append(val)\n",
        "  return q_weighting"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H96CBWdobell"
      },
      "source": [
        "## Tf, df, idf, query weighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RwcSlVSbxKA"
      },
      "source": [
        "#Term frequency\n",
        "def termFrequency(data, tr):\n",
        "  tf = []\n",
        "  for term in tr:\n",
        "    aux = []\n",
        "    for i in range(len(data)):\n",
        "      freq = 0\n",
        "      row = data[i].lower()\n",
        "      for word in tr[term]:\n",
        "        freq += row.count(word)\n",
        "      aux.append(freq)\n",
        "    tf.append(aux)\n",
        "  return tf\n",
        "\n",
        "#Document frequency\n",
        "def documentFreq(tf):\n",
        "  df = []\n",
        "  for vector in tf:\n",
        "    freq = 0\n",
        "    for f in vector:\n",
        "      if (f>0):\n",
        "        freq += 1\n",
        "    df.append(freq)\n",
        "  return df\n",
        "\n",
        "#Inverse document frquency\n",
        "def idf(df, n, log_base=math.e):\n",
        "  idf = []\n",
        "  x = 1\n",
        "  for val in df:\n",
        "    x = 1\n",
        "    if val>0:\n",
        "      x = n/val\n",
        "    res = math.log(x, log_base)\n",
        "    idf.append(res)\n",
        "  return idf\n",
        "\n",
        "#Tf-idf weighting\n",
        "def tf_idfWeighting(tf, idf):\n",
        "  tf_idf = []\n",
        "  for j in range(len(tf)):\n",
        "    aux = []\n",
        "    for i in range(len(tf[j])):\n",
        "      aux.append(tf[j][i]*idf[j])\n",
        "    tf_idf.append(aux)\n",
        "  return tf_idf\n",
        "\n",
        "def docWeighting(l1,tokens_rel):\n",
        "  tf = termFrequency(l1,tokens_rel)\n",
        "  df = documentFreq(tf)\n",
        "  _idf = idf(df, len(l1), log_base=10)\n",
        "  tf_idf = tf_idfWeighting(tf, _idf)\n",
        "  dc_weight = traspuesta(tf_idf)\n",
        "  return dc_weight"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gkBzvFBN77G"
      },
      "source": [
        "##Compressing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pRKubL0OTf5"
      },
      "source": [
        "def freqLetras(tokens):\n",
        "  letras_fr = {}\n",
        "  for i in range(97, 123):\n",
        "    n = 0\n",
        "    for token in tokens:\n",
        "      n += token.count(chr(i))\n",
        "    letras_fr[chr(i)] = n\n",
        "  letras_fr = sortDicValues(letras_fr, rev=True)\n",
        "  return letras_fr\n",
        "\n",
        "#Code for compressing\n",
        "def compressCode(letras):\n",
        "  code = {}\n",
        "  cad = '0'\n",
        "  for l in letras:\n",
        "    cad += '1'\n",
        "    code[l] = cad\n",
        "  return code\n",
        "\n",
        "#Compress\n",
        "def compress(tokens):\n",
        "  letras_fr = freqLetras(tokens)\n",
        "  letras = compressCode(letras_fr)\n",
        "  cmp_string = ''\n",
        "  for word in tokens:\n",
        "    cmp_string += str(len(word))\n",
        "    for w in word:\n",
        "      if w in letras.keys():\n",
        "        cmp_string += letras[w]\n",
        "  return cmp_string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3x6rJqXcIN3"
      },
      "source": [
        "## Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oojbxk2YcPqj"
      },
      "source": [
        "#Documents similarity\n",
        "def similitud_doc(matriz):\n",
        "  sim = []\n",
        "  for v1 in matriz:\n",
        "    v = []\n",
        "    for v2 in matriz:\n",
        "      val = similarity(v1, v2)\n",
        "      v.append(val)\n",
        "    sim.append(v)\n",
        "  return sim\n",
        "\n",
        "def similarity(v1, v2):\n",
        "  dp = dot(v1,v2)\n",
        "  n1 = norma(v1)\n",
        "  n2 = norma(v2)\n",
        "  sml = dp/(n1*n2)\n",
        "  return sml\n",
        "\n",
        "#Dot product between two vectors\n",
        "def dot(v1, v2):\n",
        "  dp = 0\n",
        "  for i in range(len(v1)):\n",
        "    dp += (v1[i]*v2[i])\n",
        "  return dp\n",
        "\n",
        "#Norm of a vector\n",
        "def norma(vect):\n",
        "  suma = 0\n",
        "  for x in vect:\n",
        "    suma += (x**2)\n",
        "  return math.sqrt(suma)\n",
        "\n",
        "#Order by similarity\n",
        "def simSort(rtr, qw, mtr):\n",
        "  dct = {}\n",
        "  for i in rtr:\n",
        "    vector = mtr[i]\n",
        "    sim = similarity(qw, vector)\n",
        "    dct[sim] = i\n",
        "  dct = sortDic(dct, rev=True)\n",
        "  return list(dct.values())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LE1sG8ZqsKo"
      },
      "source": [
        "## Clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y0CiTL3q4lr"
      },
      "source": [
        "#Create clusters using standard deviation\n",
        "def clusteringSTD(simM, s):\n",
        "  ctr = []\n",
        "  clusters = []\n",
        "  length = len(simM)\n",
        "  std_index, std = stdIndex(simM)\n",
        "  while len(std_index)>0:\n",
        "    ind = std_index.pop(0)\n",
        "    if inClusters(ind, clusters):\n",
        "      continue\n",
        "    clusters.append(createClusterS(ind, simM, s))\n",
        "    ctr.append(ind)\n",
        "  return clusters, ctr\n",
        "\n",
        "#Create clusters\n",
        "def clustering(smlM, s):\n",
        "  ctr = []\n",
        "  clusters = []\n",
        "  length = len(smlM)\n",
        "  for i in range(length):\n",
        "    if not inClusters(i, clusters):\n",
        "      clusters.append(createClusterS(i, smlM, s))\n",
        "      ctr.append(i)\n",
        "  return clusters, ctr\n",
        "\n",
        "#Create cluster with n elements\n",
        "def createClusterN(doc, dw, n):\n",
        "  dic_sim = {}\n",
        "  v_sim = dw[doc]\n",
        "  for i in range(len(v_sim)):\n",
        "    key = v_sim[i]\n",
        "    dic_sim[key] = i\n",
        "  dic_sim = sortDic(dic_sim, rev=True)\n",
        "  cluster = [doc]\n",
        "  values = list(dic_sim.values())\n",
        "  for i in range(n-1):\n",
        "    cluster.append(values[i])\n",
        "  return cluster\n",
        "\n",
        "#Create clustes with documents with similarity greater than or equal to s\n",
        "def createClusterS(doc, sml, s):\n",
        "  dic_sim = {}\n",
        "  v_sim = sml[doc]\n",
        "  for i in range(len(v_sim)):\n",
        "    dic_sim[i] = v_sim[i]\n",
        "  cluster = [doc]\n",
        "  for i,val in dic_sim.items():\n",
        "    if val>=s:\n",
        "      cluster.append(i)\n",
        "  return cluster\n",
        "\n",
        "#Returns true if doc is in a cluster, and false otherwise\n",
        "def inClusters(doc, clusters):\n",
        "  for cluster in clusters:\n",
        "    if doc in cluster:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "#Returns de index of the cluster with it's main element as the most similar to doc\n",
        "def getSimCluster(sml, ctr, doc):\n",
        "  s = 0\n",
        "  ind = 0\n",
        "  for i in range(len(ctr)):\n",
        "    c = ctr[i]\n",
        "    if sml[doc][c]>s:\n",
        "      s = sml[doc][c]\n",
        "      ind = i\n",
        "  return ind\n",
        "\n",
        "#Returns a list of clusters most similar to the documents in docs\n",
        "def getClusters(sml, ctr, docs):\n",
        "  ind = []\n",
        "  for doc in docs:\n",
        "    i = getSimCluster(sml, ctr, doc)\n",
        "    if i not in ind:\n",
        "      ind.append(i)\n",
        "  ind.sort()\n",
        "  return ind"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoaoqU0FHLPF"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itemdata = []\n",
        "json_file = open('/content/gdrive/My Drive/arxiv-physics.json', 'r')\n",
        "lines = json_file.readlines()\n",
        "for line in lines:\n",
        "  itemdata.append(json.loads(line))"
      ],
      "metadata": {
        "id": "6sYk5SCxXpWR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = []\n",
        "abstract = []\n",
        "for item in itemdata:\n",
        "  ids.append(item[\"id\"])\n",
        "  abstr = item[\"abstract\"]\n",
        "  abstract.append(abstr.upper())"
      ],
      "metadata": {
        "id": "hF4nGx_xDPlu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {\n",
        "    'Physics' : ['astro-ph', 'cond-mat', 'gr-qc', 'hep-ex', 'hep-lat', 'hep-ph', 'hep-th', 'math-ph', 'nlin', 'nucl-ex', 'nucl-th', 'physics', 'quant-ph'],\n",
        "    'Mathemathics' : ['math'],\n",
        "    'Computer Science' : ['CoRR'],\n",
        "    'Quantitative Biology' : ['q-bio'],\n",
        "    'Quantitative Finance' : ['q-fin'],\n",
        "    'Statistics' : ['stat'],\n",
        "    'Electrical Engineering and Systems Science' : ['eess'],\n",
        "    'Economics' : ['econ']\n",
        "}\n",
        "physics_subc = {\n",
        "    'astro-ph' : 'Astrophysics', \n",
        "    'cond-mat' : 'Condensed Matter', \n",
        "    'gr-qc' : 'General Relativity and Quantum Cosmology', \n",
        "    'hep-ex' : 'High Energy Physics - Experiment', \n",
        "    'hep-lat' : 'High Energy Physcics - Lattice', \n",
        "    'hep-ph' : 'High Energy Physics - Phenomenology', \n",
        "    'hep-th' : 'High Energy Physics - Theory', \n",
        "    'math-ph' : 'Mathematical Physics', \n",
        "    'nlin' : 'Nonlinear Sciences', \n",
        "    'nucl-ex' : 'Nuclear Experiment', \n",
        "    'nucl-th' : 'Nuclear Theory', \n",
        "    'physics' : 'Physics', \n",
        "    'quant-ph' : 'Quantum Physics'\n",
        "}\n"
      ],
      "metadata": {
        "id": "OGak1jQZZCZs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVf_S9feGOQ5"
      },
      "source": [
        "#Documents preprocessing\n",
        "abstract2 = remove_d(abstract[:1000])\n",
        "tokens_rel, tokens_index = tokenize(abstract2)\n",
        "posting_list = crearPL(tokens_rel, abstract2)\n",
        "tokens_cmp = compress(tokens_rel)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuJHc9frZDwR"
      },
      "source": [
        "#Documents preprocessing\n",
        "doc_weights = docWeighting(abstract2, tokens_rel)\n",
        "sml = similitud_doc(doc_weights)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2TaWqAzz8Gd"
      },
      "source": [
        "#Creates clusters\n",
        "clusters,ctr = clustering(sml, 0.15)\n",
        "#Creates clusters using standard deviation\n",
        "clusters_std,ctr_std = clusteringSTD(sml, 0.15)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDHUaBR6Tt_",
        "outputId": "23e98436-f86c-4ce1-e04d-ddcda947f3b2"
      },
      "source": [
        "#Number of clusters\n",
        "print(len(clusters))\n",
        "print(len(clusters_std))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297\n",
            "214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_jKm8hT1nHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62677cea-982f-43ca-ad0c-09a7f016d8b9"
      },
      "source": [
        "#Clusters intersection with cluster y\n",
        "y = 100\n",
        "for i in range(len(clusters)):\n",
        "  inter = intersection(clusters[y], clusters[i])\n",
        "  print(str(i)+':', len(inter))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 0\n",
            "1: 0\n",
            "2: 0\n",
            "3: 0\n",
            "4: 0\n",
            "5: 1\n",
            "6: 0\n",
            "7: 0\n",
            "8: 1\n",
            "9: 0\n",
            "10: 0\n",
            "11: 0\n",
            "12: 0\n",
            "13: 0\n",
            "14: 0\n",
            "15: 0\n",
            "16: 0\n",
            "17: 0\n",
            "18: 0\n",
            "19: 0\n",
            "20: 0\n",
            "21: 0\n",
            "22: 0\n",
            "23: 0\n",
            "24: 0\n",
            "25: 0\n",
            "26: 0\n",
            "27: 0\n",
            "28: 0\n",
            "29: 0\n",
            "30: 0\n",
            "31: 0\n",
            "32: 0\n",
            "33: 1\n",
            "34: 0\n",
            "35: 0\n",
            "36: 0\n",
            "37: 0\n",
            "38: 0\n",
            "39: 0\n",
            "40: 0\n",
            "41: 0\n",
            "42: 0\n",
            "43: 0\n",
            "44: 1\n",
            "45: 0\n",
            "46: 0\n",
            "47: 0\n",
            "48: 0\n",
            "49: 0\n",
            "50: 0\n",
            "51: 0\n",
            "52: 1\n",
            "53: 0\n",
            "54: 0\n",
            "55: 0\n",
            "56: 0\n",
            "57: 0\n",
            "58: 0\n",
            "59: 0\n",
            "60: 0\n",
            "61: 0\n",
            "62: 0\n",
            "63: 0\n",
            "64: 0\n",
            "65: 0\n",
            "66: 1\n",
            "67: 0\n",
            "68: 0\n",
            "69: 0\n",
            "70: 0\n",
            "71: 0\n",
            "72: 0\n",
            "73: 0\n",
            "74: 0\n",
            "75: 0\n",
            "76: 0\n",
            "77: 0\n",
            "78: 1\n",
            "79: 0\n",
            "80: 0\n",
            "81: 0\n",
            "82: 0\n",
            "83: 0\n",
            "84: 0\n",
            "85: 0\n",
            "86: 1\n",
            "87: 0\n",
            "88: 0\n",
            "89: 1\n",
            "90: 0\n",
            "91: 1\n",
            "92: 0\n",
            "93: 0\n",
            "94: 0\n",
            "95: 0\n",
            "96: 0\n",
            "97: 0\n",
            "98: 0\n",
            "99: 0\n",
            "100: 21\n",
            "101: 0\n",
            "102: 0\n",
            "103: 0\n",
            "104: 0\n",
            "105: 3\n",
            "106: 0\n",
            "107: 0\n",
            "108: 0\n",
            "109: 0\n",
            "110: 1\n",
            "111: 0\n",
            "112: 0\n",
            "113: 0\n",
            "114: 0\n",
            "115: 0\n",
            "116: 0\n",
            "117: 0\n",
            "118: 0\n",
            "119: 0\n",
            "120: 0\n",
            "121: 0\n",
            "122: 0\n",
            "123: 0\n",
            "124: 0\n",
            "125: 0\n",
            "126: 2\n",
            "127: 0\n",
            "128: 2\n",
            "129: 1\n",
            "130: 0\n",
            "131: 1\n",
            "132: 0\n",
            "133: 2\n",
            "134: 0\n",
            "135: 0\n",
            "136: 0\n",
            "137: 0\n",
            "138: 0\n",
            "139: 0\n",
            "140: 0\n",
            "141: 1\n",
            "142: 1\n",
            "143: 0\n",
            "144: 0\n",
            "145: 0\n",
            "146: 1\n",
            "147: 0\n",
            "148: 0\n",
            "149: 0\n",
            "150: 0\n",
            "151: 0\n",
            "152: 0\n",
            "153: 0\n",
            "154: 0\n",
            "155: 0\n",
            "156: 1\n",
            "157: 1\n",
            "158: 0\n",
            "159: 0\n",
            "160: 0\n",
            "161: 0\n",
            "162: 0\n",
            "163: 0\n",
            "164: 0\n",
            "165: 0\n",
            "166: 0\n",
            "167: 0\n",
            "168: 1\n",
            "169: 0\n",
            "170: 0\n",
            "171: 0\n",
            "172: 0\n",
            "173: 0\n",
            "174: 0\n",
            "175: 0\n",
            "176: 0\n",
            "177: 0\n",
            "178: 0\n",
            "179: 0\n",
            "180: 0\n",
            "181: 0\n",
            "182: 0\n",
            "183: 0\n",
            "184: 0\n",
            "185: 0\n",
            "186: 0\n",
            "187: 0\n",
            "188: 0\n",
            "189: 0\n",
            "190: 0\n",
            "191: 0\n",
            "192: 0\n",
            "193: 0\n",
            "194: 0\n",
            "195: 0\n",
            "196: 0\n",
            "197: 0\n",
            "198: 0\n",
            "199: 2\n",
            "200: 0\n",
            "201: 0\n",
            "202: 0\n",
            "203: 0\n",
            "204: 0\n",
            "205: 0\n",
            "206: 0\n",
            "207: 0\n",
            "208: 0\n",
            "209: 1\n",
            "210: 0\n",
            "211: 0\n",
            "212: 0\n",
            "213: 0\n",
            "214: 0\n",
            "215: 0\n",
            "216: 0\n",
            "217: 0\n",
            "218: 0\n",
            "219: 0\n",
            "220: 0\n",
            "221: 0\n",
            "222: 0\n",
            "223: 0\n",
            "224: 0\n",
            "225: 0\n",
            "226: 0\n",
            "227: 0\n",
            "228: 0\n",
            "229: 0\n",
            "230: 0\n",
            "231: 1\n",
            "232: 0\n",
            "233: 0\n",
            "234: 0\n",
            "235: 0\n",
            "236: 0\n",
            "237: 0\n",
            "238: 0\n",
            "239: 0\n",
            "240: 0\n",
            "241: 0\n",
            "242: 1\n",
            "243: 0\n",
            "244: 0\n",
            "245: 0\n",
            "246: 0\n",
            "247: 2\n",
            "248: 0\n",
            "249: 1\n",
            "250: 0\n",
            "251: 0\n",
            "252: 0\n",
            "253: 0\n",
            "254: 0\n",
            "255: 1\n",
            "256: 0\n",
            "257: 0\n",
            "258: 0\n",
            "259: 0\n",
            "260: 0\n",
            "261: 0\n",
            "262: 0\n",
            "263: 0\n",
            "264: 0\n",
            "265: 0\n",
            "266: 0\n",
            "267: 0\n",
            "268: 1\n",
            "269: 0\n",
            "270: 0\n",
            "271: 0\n",
            "272: 0\n",
            "273: 0\n",
            "274: 0\n",
            "275: 0\n",
            "276: 1\n",
            "277: 0\n",
            "278: 0\n",
            "279: 0\n",
            "280: 0\n",
            "281: 0\n",
            "282: 0\n",
            "283: 0\n",
            "284: 0\n",
            "285: 0\n",
            "286: 0\n",
            "287: 0\n",
            "288: 0\n",
            "289: 0\n",
            "290: 0\n",
            "291: 0\n",
            "292: 0\n",
            "293: 0\n",
            "294: 0\n",
            "295: 0\n",
            "296: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DIbU82AjUZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989ac3da-d346-456c-f12f-da772882b698"
      },
      "source": [
        "#Clusters (made with the standard deviation) intersection with cluster y\n",
        "y = 100\n",
        "for i in range(len(clusters_std)):\n",
        "  inter = intersection(clusters_std[y], clusters_std[i])\n",
        "  print(str(i)+':', len(inter))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2\n",
            "1: 0\n",
            "2: 0\n",
            "3: 0\n",
            "4: 0\n",
            "5: 0\n",
            "6: 0\n",
            "7: 1\n",
            "8: 0\n",
            "9: 0\n",
            "10: 0\n",
            "11: 0\n",
            "12: 0\n",
            "13: 0\n",
            "14: 0\n",
            "15: 0\n",
            "16: 0\n",
            "17: 0\n",
            "18: 0\n",
            "19: 0\n",
            "20: 0\n",
            "21: 0\n",
            "22: 3\n",
            "23: 0\n",
            "24: 0\n",
            "25: 3\n",
            "26: 0\n",
            "27: 0\n",
            "28: 0\n",
            "29: 0\n",
            "30: 0\n",
            "31: 0\n",
            "32: 0\n",
            "33: 0\n",
            "34: 1\n",
            "35: 0\n",
            "36: 1\n",
            "37: 0\n",
            "38: 0\n",
            "39: 0\n",
            "40: 1\n",
            "41: 0\n",
            "42: 0\n",
            "43: 0\n",
            "44: 0\n",
            "45: 0\n",
            "46: 1\n",
            "47: 0\n",
            "48: 0\n",
            "49: 0\n",
            "50: 0\n",
            "51: 0\n",
            "52: 0\n",
            "53: 0\n",
            "54: 0\n",
            "55: 0\n",
            "56: 0\n",
            "57: 0\n",
            "58: 0\n",
            "59: 1\n",
            "60: 0\n",
            "61: 0\n",
            "62: 1\n",
            "63: 0\n",
            "64: 0\n",
            "65: 0\n",
            "66: 0\n",
            "67: 0\n",
            "68: 0\n",
            "69: 0\n",
            "70: 0\n",
            "71: 0\n",
            "72: 0\n",
            "73: 1\n",
            "74: 0\n",
            "75: 0\n",
            "76: 0\n",
            "77: 0\n",
            "78: 0\n",
            "79: 0\n",
            "80: 0\n",
            "81: 0\n",
            "82: 0\n",
            "83: 0\n",
            "84: 0\n",
            "85: 1\n",
            "86: 0\n",
            "87: 0\n",
            "88: 0\n",
            "89: 0\n",
            "90: 0\n",
            "91: 0\n",
            "92: 0\n",
            "93: 0\n",
            "94: 0\n",
            "95: 0\n",
            "96: 0\n",
            "97: 0\n",
            "98: 2\n",
            "99: 0\n",
            "100: 9\n",
            "101: 0\n",
            "102: 0\n",
            "103: 0\n",
            "104: 0\n",
            "105: 1\n",
            "106: 0\n",
            "107: 0\n",
            "108: 0\n",
            "109: 0\n",
            "110: 0\n",
            "111: 0\n",
            "112: 0\n",
            "113: 0\n",
            "114: 0\n",
            "115: 0\n",
            "116: 0\n",
            "117: 1\n",
            "118: 0\n",
            "119: 0\n",
            "120: 0\n",
            "121: 0\n",
            "122: 0\n",
            "123: 0\n",
            "124: 0\n",
            "125: 0\n",
            "126: 0\n",
            "127: 0\n",
            "128: 0\n",
            "129: 0\n",
            "130: 2\n",
            "131: 0\n",
            "132: 0\n",
            "133: 0\n",
            "134: 1\n",
            "135: 0\n",
            "136: 0\n",
            "137: 0\n",
            "138: 0\n",
            "139: 0\n",
            "140: 0\n",
            "141: 0\n",
            "142: 0\n",
            "143: 0\n",
            "144: 0\n",
            "145: 0\n",
            "146: 1\n",
            "147: 0\n",
            "148: 2\n",
            "149: 0\n",
            "150: 0\n",
            "151: 0\n",
            "152: 0\n",
            "153: 0\n",
            "154: 0\n",
            "155: 0\n",
            "156: 0\n",
            "157: 0\n",
            "158: 0\n",
            "159: 0\n",
            "160: 0\n",
            "161: 1\n",
            "162: 0\n",
            "163: 0\n",
            "164: 0\n",
            "165: 0\n",
            "166: 0\n",
            "167: 0\n",
            "168: 0\n",
            "169: 0\n",
            "170: 0\n",
            "171: 0\n",
            "172: 0\n",
            "173: 0\n",
            "174: 0\n",
            "175: 0\n",
            "176: 0\n",
            "177: 0\n",
            "178: 0\n",
            "179: 0\n",
            "180: 0\n",
            "181: 0\n",
            "182: 0\n",
            "183: 0\n",
            "184: 1\n",
            "185: 0\n",
            "186: 0\n",
            "187: 0\n",
            "188: 0\n",
            "189: 0\n",
            "190: 0\n",
            "191: 0\n",
            "192: 0\n",
            "193: 0\n",
            "194: 0\n",
            "195: 0\n",
            "196: 0\n",
            "197: 0\n",
            "198: 0\n",
            "199: 0\n",
            "200: 1\n",
            "201: 0\n",
            "202: 0\n",
            "203: 0\n",
            "204: 0\n",
            "205: 0\n",
            "206: 0\n",
            "207: 0\n",
            "208: 0\n",
            "209: 0\n",
            "210: 0\n",
            "211: 0\n",
            "212: 0\n",
            "213: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rthxC7sRqlof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e3ff16-93d2-44e2-d9ee-bb9fed0c33fd"
      },
      "source": [
        "#Size of each cluster\n",
        "for i in range(len(clusters_std)):\n",
        "  print(str(i)+': '+str(len(clusters_std[i])))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 61\n",
            "1: 9\n",
            "2: 24\n",
            "3: 5\n",
            "4: 48\n",
            "5: 7\n",
            "6: 27\n",
            "7: 15\n",
            "8: 26\n",
            "9: 6\n",
            "10: 18\n",
            "11: 4\n",
            "12: 9\n",
            "13: 13\n",
            "14: 19\n",
            "15: 5\n",
            "16: 7\n",
            "17: 13\n",
            "18: 16\n",
            "19: 16\n",
            "20: 2\n",
            "21: 7\n",
            "22: 17\n",
            "23: 3\n",
            "24: 16\n",
            "25: 12\n",
            "26: 8\n",
            "27: 7\n",
            "28: 10\n",
            "29: 11\n",
            "30: 10\n",
            "31: 9\n",
            "32: 5\n",
            "33: 4\n",
            "34: 12\n",
            "35: 14\n",
            "36: 12\n",
            "37: 3\n",
            "38: 28\n",
            "39: 17\n",
            "40: 9\n",
            "41: 7\n",
            "42: 13\n",
            "43: 16\n",
            "44: 8\n",
            "45: 6\n",
            "46: 3\n",
            "47: 10\n",
            "48: 12\n",
            "49: 7\n",
            "50: 21\n",
            "51: 12\n",
            "52: 4\n",
            "53: 11\n",
            "54: 5\n",
            "55: 8\n",
            "56: 3\n",
            "57: 2\n",
            "58: 19\n",
            "59: 13\n",
            "60: 9\n",
            "61: 2\n",
            "62: 12\n",
            "63: 18\n",
            "64: 9\n",
            "65: 4\n",
            "66: 5\n",
            "67: 5\n",
            "68: 5\n",
            "69: 7\n",
            "70: 8\n",
            "71: 7\n",
            "72: 3\n",
            "73: 10\n",
            "74: 7\n",
            "75: 5\n",
            "76: 4\n",
            "77: 4\n",
            "78: 4\n",
            "79: 6\n",
            "80: 8\n",
            "81: 8\n",
            "82: 6\n",
            "83: 8\n",
            "84: 15\n",
            "85: 12\n",
            "86: 8\n",
            "87: 5\n",
            "88: 11\n",
            "89: 12\n",
            "90: 2\n",
            "91: 21\n",
            "92: 16\n",
            "93: 5\n",
            "94: 10\n",
            "95: 3\n",
            "96: 6\n",
            "97: 4\n",
            "98: 8\n",
            "99: 9\n",
            "100: 9\n",
            "101: 9\n",
            "102: 9\n",
            "103: 4\n",
            "104: 25\n",
            "105: 7\n",
            "106: 3\n",
            "107: 3\n",
            "108: 11\n",
            "109: 6\n",
            "110: 4\n",
            "111: 6\n",
            "112: 4\n",
            "113: 6\n",
            "114: 7\n",
            "115: 9\n",
            "116: 5\n",
            "117: 6\n",
            "118: 8\n",
            "119: 3\n",
            "120: 10\n",
            "121: 2\n",
            "122: 5\n",
            "123: 2\n",
            "124: 5\n",
            "125: 7\n",
            "126: 8\n",
            "127: 18\n",
            "128: 19\n",
            "129: 6\n",
            "130: 6\n",
            "131: 3\n",
            "132: 13\n",
            "133: 7\n",
            "134: 5\n",
            "135: 26\n",
            "136: 3\n",
            "137: 2\n",
            "138: 8\n",
            "139: 10\n",
            "140: 9\n",
            "141: 7\n",
            "142: 7\n",
            "143: 12\n",
            "144: 2\n",
            "145: 3\n",
            "146: 20\n",
            "147: 6\n",
            "148: 14\n",
            "149: 9\n",
            "150: 9\n",
            "151: 3\n",
            "152: 6\n",
            "153: 9\n",
            "154: 14\n",
            "155: 6\n",
            "156: 7\n",
            "157: 4\n",
            "158: 4\n",
            "159: 5\n",
            "160: 3\n",
            "161: 6\n",
            "162: 5\n",
            "163: 9\n",
            "164: 3\n",
            "165: 15\n",
            "166: 4\n",
            "167: 3\n",
            "168: 7\n",
            "169: 9\n",
            "170: 8\n",
            "171: 5\n",
            "172: 13\n",
            "173: 4\n",
            "174: 4\n",
            "175: 8\n",
            "176: 8\n",
            "177: 5\n",
            "178: 6\n",
            "179: 7\n",
            "180: 4\n",
            "181: 3\n",
            "182: 4\n",
            "183: 4\n",
            "184: 10\n",
            "185: 2\n",
            "186: 4\n",
            "187: 3\n",
            "188: 6\n",
            "189: 5\n",
            "190: 2\n",
            "191: 4\n",
            "192: 9\n",
            "193: 6\n",
            "194: 5\n",
            "195: 2\n",
            "196: 6\n",
            "197: 5\n",
            "198: 10\n",
            "199: 6\n",
            "200: 3\n",
            "201: 7\n",
            "202: 8\n",
            "203: 6\n",
            "204: 8\n",
            "205: 3\n",
            "206: 7\n",
            "207: 4\n",
            "208: 3\n",
            "209: 6\n",
            "210: 10\n",
            "211: 5\n",
            "212: 6\n",
            "213: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imB1Po_6_PYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "22063532-f267-49fd-b688-41bb706099ef"
      },
      "source": [
        "#Distribution from item x\n",
        "x = 500\n",
        "graphDistribution(sml, x)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39M5b_gLDdbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf252c2-8341-4a64-b4de-0473db0a0d27"
      },
      "source": [
        "#Cluster elements\n",
        "for cluster in clusters_std:\n",
        "  print(cluster)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[966, 13, 78, 83, 84, 106, 122, 135, 165, 182, 183, 187, 238, 246, 291, 301, 331, 341, 364, 371, 377, 414, 421, 449, 451, 458, 460, 468, 469, 511, 524, 531, 590, 599, 613, 618, 638, 640, 644, 688, 690, 709, 713, 716, 741, 753, 757, 816, 829, 864, 899, 904, 923, 929, 937, 943, 954, 964, 966, 973, 999]\n",
            "[601, 92, 166, 356, 425, 601, 700, 838, 960]\n",
            "[530, 115, 161, 215, 237, 265, 268, 401, 447, 478, 530, 621, 642, 761, 769, 815, 842, 855, 866, 949, 953, 961, 974, 991]\n",
            "[919, 90, 187, 629, 919]\n",
            "[206, 17, 114, 121, 124, 154, 157, 161, 168, 195, 202, 206, 209, 220, 234, 241, 265, 301, 310, 352, 361, 370, 419, 423, 465, 489, 498, 499, 555, 594, 611, 635, 638, 642, 654, 673, 674, 678, 728, 742, 745, 756, 769, 809, 863, 866, 895, 967]\n",
            "[958, 3, 28, 553, 824, 958, 962]\n",
            "[712, 38, 40, 94, 128, 177, 207, 235, 298, 342, 348, 354, 359, 398, 432, 491, 526, 602, 653, 679, 712, 735, 738, 818, 927, 940, 945]\n",
            "[812, 43, 80, 186, 199, 411, 615, 670, 771, 796, 812, 831, 853, 892, 914]\n",
            "[392, 12, 56, 128, 170, 184, 254, 280, 300, 392, 412, 437, 574, 664, 685, 717, 718, 729, 772, 796, 836, 875, 899, 914, 951, 959]\n",
            "[487, 13, 228, 300, 487, 591]\n",
            "[873, 8, 204, 215, 229, 235, 362, 365, 398, 618, 636, 660, 694, 697, 706, 728, 849, 873]\n",
            "[351, 314, 351, 401]\n",
            "[744, 343, 406, 492, 570, 661, 722, 744, 775]\n",
            "[592, 119, 257, 336, 448, 517, 592, 610, 615, 619, 774, 794, 865]\n",
            "[304, 0, 10, 227, 253, 304, 390, 405, 486, 489, 496, 737, 743, 754, 790, 803, 853, 970, 986]\n",
            "[338, 41, 249, 338, 488]\n",
            "[239, 56, 239, 285, 372, 664, 721]\n",
            "[641, 29, 135, 364, 401, 449, 463, 566, 641, 675, 750, 753, 965]\n",
            "[632, 51, 66, 118, 243, 369, 452, 483, 605, 632, 797, 823, 824, 845, 879, 956]\n",
            "[305, 123, 252, 260, 282, 305, 312, 331, 341, 559, 561, 757, 841, 864, 924, 929]\n",
            "[324, 324]\n",
            "[928, 142, 489, 595, 751, 820, 928]\n",
            "[297, 81, 104, 132, 270, 297, 341, 368, 489, 558, 637, 644, 651, 657, 707, 716, 856]\n",
            "[232, 232, 975]\n",
            "[450, 95, 152, 198, 223, 380, 386, 416, 450, 608, 649, 692, 739, 799, 842, 925]\n",
            "[686, 255, 270, 492, 521, 614, 686, 695, 748, 797, 830, 899]\n",
            "[178, 90, 178, 303, 385, 627, 820, 977]\n",
            "[724, 4, 314, 439, 549, 724, 904]\n",
            "[389, 42, 60, 79, 107, 117, 234, 389, 424, 707]\n",
            "[881, 62, 124, 131, 192, 401, 510, 552, 621, 881, 944]\n",
            "[387, 200, 280, 363, 387, 441, 676, 782, 796, 844]\n",
            "[917, 117, 301, 328, 675, 707, 784, 917, 964]\n",
            "[110, 10, 110, 489, 714]\n",
            "[197, 197, 229, 367]\n",
            "[645, 26, 54, 66, 172, 308, 411, 433, 554, 645, 696, 726]\n",
            "[703, 15, 107, 117, 249, 316, 344, 415, 520, 548, 703, 707, 711, 784]\n",
            "[877, 101, 105, 128, 271, 273, 281, 521, 578, 614, 722, 877]\n",
            "[586, 497, 586]\n",
            "[67, 67, 96, 168, 217, 242, 280, 307, 333, 336, 394, 572, 588, 626, 670, 693, 740, 774, 832, 851, 885, 893, 926, 947, 962, 974, 981, 997]\n",
            "[783, 13, 123, 301, 353, 364, 414, 465, 492, 539, 647, 722, 783, 859, 900, 976, 983]\n",
            "[275, 46, 275, 284, 495, 716, 868, 974, 984]\n",
            "[420, 113, 185, 226, 420, 604, 850]\n",
            "[269, 83, 102, 130, 154, 222, 269, 386, 410, 756, 930, 987, 995]\n",
            "[283, 19, 42, 139, 191, 283, 285, 299, 339, 424, 562, 623, 691, 762, 882, 950]\n",
            "[442, 405, 442, 737, 754, 775, 803, 986]\n",
            "[221, 56, 141, 221, 680, 878]\n",
            "[334, 334, 614]\n",
            "[563, 58, 92, 173, 247, 378, 563, 574, 591, 731]\n",
            "[251, 17, 63, 114, 129, 246, 251, 282, 465, 561, 659, 976]\n",
            "[869, 40, 235, 398, 735, 869, 927]\n",
            "[466, 50, 70, 79, 191, 226, 244, 252, 466, 470, 519, 544, 554, 617, 651, 656, 754, 768, 775, 803, 882]\n",
            "[848, 49, 95, 253, 278, 318, 623, 743, 765, 848, 853, 933]\n",
            "[564, 564, 603, 975]\n",
            "[146, 104, 125, 146, 360, 406, 570, 606, 675, 909, 993]\n",
            "[225, 162, 225, 431, 482]\n",
            "[77, 77, 135, 160, 218, 418, 600, 663]\n",
            "[446, 446, 581]\n",
            "[440, 440]\n",
            "[671, 161, 204, 207, 214, 362, 478, 603, 605, 618, 621, 649, 671, 694, 739, 769, 842, 855, 947]\n",
            "[240, 125, 145, 240, 312, 559, 599, 644, 695, 722, 729, 816, 937]\n",
            "[854, 161, 220, 234, 361, 423, 654, 728, 854]\n",
            "[575, 575]\n",
            "[665, 96, 106, 125, 253, 382, 422, 444, 644, 665, 816, 853]\n",
            "[584, 63, 96, 106, 125, 182, 294, 322, 360, 394, 403, 498, 554, 584, 593, 594, 599, 916]\n",
            "[201, 0, 70, 99, 131, 201, 409, 565, 924]\n",
            "[550, 75, 385, 550]\n",
            "[515, 457, 515, 607, 843]\n",
            "[134, 61, 134, 778, 862]\n",
            "[147, 147, 714, 743, 765]\n",
            "[164, 164, 361, 654, 732, 871, 953]\n",
            "[698, 153, 205, 222, 570, 698, 841, 963]\n",
            "[287, 44, 170, 280, 287, 431, 865]\n",
            "[535, 395, 535]\n",
            "[725, 54, 58, 66, 68, 107, 213, 411, 719, 725]\n",
            "[296, 2, 296, 377, 604, 741, 795]\n",
            "[677, 228, 274, 668, 677]\n",
            "[589, 85, 589, 715]\n",
            "[727, 115, 368, 727]\n",
            "[516, 474, 516, 838]\n",
            "[208, 11, 208, 532, 910, 983]\n",
            "[138, 23, 111, 118, 138, 615, 682, 956]\n",
            "[770, 37, 189, 303, 647, 770, 904, 915]\n",
            "[309, 309, 416, 449, 776, 934]\n",
            "[261, 6, 131, 234, 261, 542, 546, 627]\n",
            "[317, 15, 73, 160, 218, 316, 317, 422, 435, 454, 541, 566, 629, 710, 806]\n",
            "[69, 52, 69, 75, 200, 210, 280, 281, 363, 385, 614, 782]\n",
            "[648, 260, 506, 508, 526, 648, 761, 856]\n",
            "[388, 388, 415, 612, 682]\n",
            "[826, 56, 99, 139, 199, 345, 349, 579, 615, 826, 831]\n",
            "[481, 84, 207, 242, 362, 481, 679, 721, 736, 828, 832, 855]\n",
            "[86, 86]\n",
            "[279, 17, 63, 122, 180, 255, 265, 279, 308, 361, 379, 386, 492, 519, 566, 600, 647, 713, 829, 918, 987]\n",
            "[819, 149, 241, 290, 310, 330, 406, 498, 514, 527, 594, 606, 638, 643, 666, 819]\n",
            "[730, 631, 730, 934, 992]\n",
            "[805, 40, 94, 223, 235, 300, 355, 745, 805, 961]\n",
            "[523, 523, 721]\n",
            "[346, 93, 345, 346, 376, 972]\n",
            "[159, 3, 65, 159]\n",
            "[755, 294, 415, 572, 614, 753, 755, 830]\n",
            "[163, 163, 517, 683, 808, 811, 836, 865, 872]\n",
            "[55, 55, 270, 337, 411, 614, 644, 716, 830]\n",
            "[620, 85, 174, 220, 344, 512, 620, 673, 809]\n",
            "[807, 129, 145, 238, 414, 613, 708, 807, 922]\n",
            "[292, 143, 292, 482]\n",
            "[479, 12, 13, 135, 148, 203, 236, 264, 302, 313, 384, 427, 449, 464, 479, 621, 779, 815, 841, 868, 883, 923, 942, 954, 967]\n",
            "[476, 337, 476, 556, 579, 627, 841]\n",
            "[538, 47, 538]\n",
            "[628, 473, 628]\n",
            "[655, 92, 121, 145, 162, 166, 356, 457, 655, 683, 960]\n",
            "[503, 158, 170, 503, 573, 789]\n",
            "[267, 171, 267, 955]\n",
            "[288, 112, 288, 374, 827, 935]\n",
            "[266, 176, 266, 352]\n",
            "[513, 513, 540, 792, 897, 977]\n",
            "[408, 245, 402, 404, 408, 441, 852]\n",
            "[662, 12, 113, 468, 640, 646, 662, 874, 979]\n",
            "[528, 517, 528, 683, 684]\n",
            "[462, 35, 337, 462, 474, 630]\n",
            "[156, 156, 216, 391, 432, 738, 945, 997]\n",
            "[233, 233, 282]\n",
            "[373, 53, 214, 342, 373, 380, 416, 739, 818, 925]\n",
            "[545, 545]\n",
            "[211, 211, 245, 402, 959]\n",
            "[319, 319]\n",
            "[699, 13, 699, 722, 739]\n",
            "[417, 121, 140, 263, 417, 631, 635]\n",
            "[490, 329, 343, 382, 444, 490, 527, 988]\n",
            "[501, 5, 216, 235, 342, 362, 365, 478, 501, 581, 734, 753, 874, 878, 901, 907, 947, 961]\n",
            "[639, 46, 132, 183, 294, 306, 343, 360, 406, 460, 527, 609, 639, 658, 748, 795, 903, 909, 993]\n",
            "[20, 20, 22, 23, 24, 960]\n",
            "[534, 236, 534, 614, 759, 830]\n",
            "[357, 357, 908]\n",
            "[467, 23, 25, 70, 226, 243, 254, 329, 467, 542, 556, 931, 933]\n",
            "[98, 98, 187, 460, 521, 664, 892]\n",
            "[381, 170, 270, 381, 767]\n",
            "[509, 44, 85, 124, 140, 168, 202, 237, 268, 330, 509, 577, 618, 631, 635, 673, 678, 815, 842, 849, 863, 918, 946, 955, 968, 997]\n",
            "[543, 458, 543]\n",
            "[507, 507]\n",
            "[167, 167, 268, 728, 761, 769, 842, 847]\n",
            "[325, 144, 161, 255, 325, 428, 454, 552, 582, 690]\n",
            "[311, 123, 226, 278, 311, 368, 489, 561, 850]\n",
            "[537, 404, 537, 610, 700, 740, 859]\n",
            "[151, 151, 237, 633, 918, 983, 996]\n",
            "[179, 9, 66, 96, 179, 308, 441, 588, 718, 820, 899, 903]\n",
            "[39, 39]\n",
            "[109, 109, 670]\n",
            "[74, 74, 182, 252, 331, 404, 559, 561, 599, 609, 644, 675, 688, 722, 757, 763, 859, 924, 929, 988]\n",
            "[518, 0, 332, 499, 518, 989]\n",
            "[72, 72, 246, 301, 320, 399, 531, 549, 583, 609, 644, 716, 818, 915]\n",
            "[426, 372, 426, 447, 649, 736, 818, 925, 934]\n",
            "[445, 207, 214, 342, 359, 445, 491, 633, 894]\n",
            "[484, 484, 882]\n",
            "[194, 64, 194, 272, 732, 733]\n",
            "[585, 34, 236, 302, 384, 427, 585, 883, 983]\n",
            "[14, 14, 17, 63, 116, 149, 173, 255, 294, 301, 326, 566, 667, 674]\n",
            "[137, 137, 263, 358, 654, 871]\n",
            "[250, 200, 250, 363, 682, 782, 837]\n",
            "[33, 33, 406, 532]\n",
            "[126, 126, 160, 647]\n",
            "[438, 26, 27, 433, 438]\n",
            "[461, 461, 544]\n",
            "[568, 270, 273, 568, 847, 991]\n",
            "[286, 71, 188, 286, 604]\n",
            "[453, 70, 92, 99, 403, 453, 651, 821, 924]\n",
            "[31, 31, 837]\n",
            "[430, 41, 226, 243, 328, 375, 430, 486, 489, 612, 857, 931, 933, 941, 956]\n",
            "[400, 400, 431, 482]\n",
            "[175, 175, 480]\n",
            "[522, 522, 860, 887, 893, 894, 908]\n",
            "[477, 123, 173, 185, 340, 477, 571, 598, 941]\n",
            "[150, 127, 150, 234, 295, 582, 803, 957]\n",
            "[230, 128, 230, 581, 846]\n",
            "[120, 70, 79, 120, 405, 493, 624, 803, 813, 821, 823, 853, 924]\n",
            "[277, 188, 277, 707]\n",
            "[190, 190, 360, 844]\n",
            "[293, 8, 64, 293, 342, 581, 839, 945]\n",
            "[347, 102, 222, 244, 341, 347, 422, 795]\n",
            "[327, 104, 327, 623, 787]\n",
            "[196, 188, 196, 393, 695, 929]\n",
            "[443, 439, 443, 498, 505, 548, 553]\n",
            "[45, 45, 597, 963]\n",
            "[323, 323, 820]\n",
            "[383, 383, 428, 433]\n",
            "[321, 118, 321, 519]\n",
            "[108, 108, 166, 180, 188, 337, 425, 700, 960, 998]\n",
            "[219, 219]\n",
            "[155, 155, 290, 548]\n",
            "[88, 88, 802]\n",
            "[407, 21, 112, 253, 407, 935]\n",
            "[7, 7, 49, 765, 821]\n",
            "[256, 256]\n",
            "[1, 1, 361, 764]\n",
            "[103, 103, 141, 301, 310, 396, 406, 498, 520]\n",
            "[89, 89, 332, 739, 769, 961]\n",
            "[76, 76, 406, 795, 988]\n",
            "[59, 59]\n",
            "[82, 21, 82, 284, 756, 995]\n",
            "[231, 136, 231, 787, 841]\n",
            "[224, 22, 51, 111, 224, 366, 471, 598, 795, 860]\n",
            "[248, 248, 343, 406, 993, 996]\n",
            "[48, 48, 337]\n",
            "[133, 24, 133, 313, 344, 367, 548]\n",
            "[16, 16, 41, 70, 429, 651, 902, 924]\n",
            "[212, 212, 265, 361, 866, 972]\n",
            "[100, 56, 100, 158, 315, 397, 458, 789]\n",
            "[87, 87, 356]\n",
            "[169, 169, 226, 295, 367, 612, 939]\n",
            "[32, 32, 687, 731]\n",
            "[30, 30, 258]\n",
            "[36, 36, 160, 218, 454, 905]\n",
            "[97, 92, 97, 99, 162, 166, 425, 700, 929, 960]\n",
            "[91, 91, 795, 840, 981]\n",
            "[18, 18, 555, 750, 793, 814]\n",
            "[57, 57, 90, 271, 941]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of query\n",
        "retrieved, q_tkr = query('cosmology', posting_list, tokens_index)\n",
        "print(retrieved)\n",
        "print(abstract[retrieved[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a0MIe1aWwKy",
        "outputId": "25341a1d-171c-4547-e18f-58a08050c7e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 56, 101, 163, 170, 437, 503, 521, 591, 592, 631, 683, 705, 789, 872, 877]\n",
            "  SINCE THE PAST IAGRG MEETING IN DECEMBER 2004, NEW DEVELOPMENTS IN LOOP\n",
            "QUANTUM COSMOLOGY HAVE TAKEN PLACE, ESPECIALLY WITH REGARDS TO THE RESOLUTION\n",
            "OF THE BIG BANG SINGULARITY IN THE ISOTROPIC MODELS. THE SINGULARITY RESOLUTION\n",
            "ISSUE HAS BEEN DISCUSSED IN TERMS OF PHYSICAL QUANTITIES (EXPECTATION VALUES OF\n",
            "DIRAC OBSERVABLES) AND THERE IS ALSO AN ``IMPROVED'' QUANTIZATION OF THE\n",
            "HAMILTONIAN CONSTRAINT. THESE DEVELOPMENTS ARE BRIEFLY DISCUSSED.\n",
            "  THIS IS AN EXPANDED VERSION OF THE REVIEW TALK GIVEN AT THE\n",
            "24$^{\\MATHRM{TH}}$ IAGRG MEETING IN FEBRUARY 2007.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints information of the results from de query\n",
        "print_info_lst(retrieved, itemdata, physics_subc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-toO6w9zbFOn",
        "outputId": "6c7ee475-3ae3-48b1-bebb-7637a752cc15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "Title: Polymer Quantum Mechanics and its Continuum Limit\n",
            "Authors: Alejandro Corichi, Tatjana Vukasinac and Jose A. Zapata\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: 10.1103/PhysRevD.76.044016\n",
            "  A rather non-standard quantum representation of the canonical commutation\n",
            "relations of quantum mechanics systems, known as the polymer representation has\n",
            "gained some attention in recent years, due to its possible relation with Planck\n",
            "scale physics. In particular, this approach has been followed in a symmetric\n",
            "sector of loop quantum gravity known as loop quantum cosmology. Here we explore\n",
            "different aspects of the relation between the ordinary Schroedinger theory and\n",
            "the polymer description. The paper has two parts. In the first one, we derive\n",
            "the polymer quantum mechanics starting from the ordinary Schroedinger theory\n",
            "and show that the polymer description arises as an appropriate limit. In the\n",
            "second part we consider the continuum limit of this theory, namely, the reverse\n",
            "process in which one starts from the discrete theory and tries to recover back\n",
            "the ordinary Schroedinger quantum mechanics. We consider several examples of\n",
            "interest, including the harmonic oscillator, the free particle and a simple\n",
            "cosmological model.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Why there is something rather than nothing (out of everything)?\n",
            "Authors: A.O.Barvinsky\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevLett.99.071301\n",
            "  The path integral over Euclidean geometries for the recently suggested\n",
            "density matrix of the Universe is shown to describe a microcanonical ensemble\n",
            "in quantum cosmology. This ensemble corresponds to a uniform (weight one)\n",
            "distribution in phase space of true physical variables, but in terms of the\n",
            "observable spacetime geometry it is peaked about complex saddle-points of the\n",
            "{\\em Lorentzian} path integral. They are represented by the recently obtained\n",
            "cosmological instantons limited to a bounded range of the cosmological\n",
            "constant. Inflationary cosmologies generated by these instantons at late stages\n",
            "of expansion undergo acceleration whose low-energy scale can be attained within\n",
            "the concept of dynamically evolving extra dimensions. Thus, together with the\n",
            "bounded range of the early cosmological constant, this cosmological ensemble\n",
            "suggests the mechanism of constraining the landscape of string vacua and,\n",
            "simultaneously, a possible solution to the dark energy problem in the form of\n",
            "the quasi-equilibrium decay of the microcanonical state of the Universe.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Singularity Resolution in Isotropic Loop Quantum Cosmology: Recent\n",
            "  Developments\n",
            "Authors: Ghanashyam Date\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: None\n",
            "  Since the past Iagrg meeting in December 2004, new developments in loop\n",
            "quantum cosmology have taken place, especially with regards to the resolution\n",
            "of the Big Bang singularity in the isotropic models. The singularity resolution\n",
            "issue has been discussed in terms of physical quantities (expectation values of\n",
            "Dirac observables) and there is also an ``improved'' quantization of the\n",
            "Hamiltonian constraint. These developments are briefly discussed.\n",
            "  This is an expanded version of the review talk given at the\n",
            "24$^{\\mathrm{th}}$ IAGRG meeting in February 2007.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: The Return of a Static Universe and the End of Cosmology\n",
            "Authors: Lawrence M. Krauss (1,2) and Robert J. Scherrer (2) ((1) Case Western\n",
            "  Reserve University, (2) Vanderbilt University)\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1007/s10714-007-0472-9 10.1142/S0218271808012449\n",
            "  We demonstrate that as we extrapolate the current $\\Lambda$CDM universe\n",
            "forward in time, all evidence of the Hubble expansion will disappear, so that\n",
            "observers in our \"island universe\" will be fundamentally incapable of\n",
            "determining the true nature of the universe, including the existence of the\n",
            "highly dominant vacuum energy, the existence of the CMB, and the primordial\n",
            "origin of light elements. With these pillars of the modern Big Bang gone, this\n",
            "epoch will mark the end of cosmology and the return of a static universe. In\n",
            "this sense, the coordinate system appropriate for future observers will perhaps\n",
            "fittingly resemble the static coordinate system in which the de Sitter universe\n",
            "was first presented.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Einstein vs Maxwell: Is gravitation a curvature of space, a field in\n",
            "  flat space, or both?\n",
            "Authors: Theo M. Nieuwenhuizen\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, Quantum Physics\n",
            "Doi: 10.1209/0295-5075/78/10010\n",
            "  Starting with a field theoretic approach in Minkowski space, the\n",
            "gravitational energy momentum tensor is derived from the Einstein equations in\n",
            "a straightforward manner. This allows to present them as {\\it acceleration\n",
            "tensor} = const. $\\times$ {\\it total energy momentum tensor}. For flat space\n",
            "cosmology the gravitational energy is negative and cancels the material energy.\n",
            "In the relativistic theory of gravitation a bimetric coupling between the\n",
            "Riemann and Minkowski metrics breaks general coordinate invariance. The case of\n",
            "a positive cosmological constant is considered. A singularity free version of\n",
            "the Schwarzschild black hole is solved analytically. In the interior the\n",
            "components of the metric tensor quickly die out, but do not change sign,\n",
            "leaving the role of time as usual. For cosmology the $\\Lambda$CDM model is\n",
            "covered, while there appears a form of inflation at early times. Here both the\n",
            "total energy and the zero point energy vanish.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Universe Without Singularities. A Group Approach to De Sitter Cosmology\n",
            "Authors: Ignazio Licata\n",
            "Categories: Physics\n",
            "Doi: None\n",
            "  In the last years the traditional scenario of Big Bang has been deeply\n",
            "modified by the study of the quantum features of the Universe evolution,\n",
            "proposing again the problem of using local physical laws on cosmic scale, with\n",
            "particular regard to the cosmological constant role. The group extention method\n",
            "shows that the De Sitter group univocally generalizes the Poincare group,\n",
            "formally justifies the cosmological constant use and suggests a new\n",
            "interpretation for Hartle-Hawking boundary conditions in Quantum Cosmology.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Testing String Theory with CMB\n",
            "Authors: Renata Kallosh and Andrei Linde\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1088/1475-7516/2007/04/017\n",
            "  Future detection/non-detection of tensor modes from inflation in CMB\n",
            "observations presents a unique way to test certain features of string theory.\n",
            "Current limit on the ratio of tensor to scalar perturbations, r=T/S, is r <\n",
            "0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all\n",
            "known string theory inflation models predict tensor modes well below the level\n",
            "of detection. Therefore a possible experimental discovery of tensor modes may\n",
            "present a challenge to string cosmology.\n",
            "  The strongest bound on r in string inflation follows from the observation\n",
            "that in most of the models based on the KKLT construction, the value of the\n",
            "Hubble constant H during inflation must be smaller than the gravitino mass. For\n",
            "the gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an\n",
            "extremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r\n",
            "> 10^{-3} would imply that the gravitinos in this class of models are\n",
            "superheavy, m_{3/2} > 10^{13} GeV. This would have important implications for\n",
            "particle phenomenology based on string theory.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Hamiltonian formalism in Friedmann cosmology and its quantization\n",
            "Authors: Jie Ren, Xin-He Meng, Liu Zhao\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.043521\n",
            "  We propose a Hamiltonian formalism for a generalized\n",
            "Friedmann-Roberson-Walker cosmology model in the presence of both a variable\n",
            "equation of state (EOS) parameter $w(a)$ and a variable cosmological constant\n",
            "$\\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing\n",
            "1 degree of freedom and without constraint, gives Friedmann equations as the\n",
            "equation of motion, which describes a mechanical system with a variable mass\n",
            "object moving in a potential field. After an appropriate transformation of the\n",
            "scale factor, this system can be further simplified to an object with constant\n",
            "mass moving in an effective potential field. In this framework, the $\\Lambda$\n",
            "cold dark matter model as the current standard model of cosmology corresponds\n",
            "to a harmonic oscillator. We further generalize this formalism to take into\n",
            "account the bulk viscosity and other cases. The Hamiltonian can be quantized\n",
            "straightforwardly, but this is different from the approach of the\n",
            "Wheeler-DeWitt equation in quantum cosmology.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: General Relativity Today\n",
            "Authors: Thibault Damour\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: 10.1007/978-3-7643-8524-8_1\n",
            "  After recalling the conceptual foundations and the basic structure of general\n",
            "relativity, we review some of its main modern developments (apart from\n",
            "cosmology) : (i) the post-Newtonian limit and weak-field tests in the solar\n",
            "system, (ii) strong gravitational fields and black holes, (iii) strong-field\n",
            "and radiative tests in binary pulsar observations, (iv) gravitational waves,\n",
            "(v) general relativity and quantum theory.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: The dynamical Casimir effect in braneworlds\n",
            "Authors: Ruth Durrer and Marcus Ruser\n",
            "Categories: Astrophysics, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevLett.99.071601\n",
            "  In braneworld cosmology the expanding Universe is realized as a brane moving\n",
            "through a warped higher-dimensional spacetime. Like a moving mirror causes the\n",
            "creation of photons out of vacuum fluctuations, a moving brane leads to\n",
            "graviton production. We show that, very generically, Kaluza-Klein (KK)\n",
            "particles scale like stiff matter with the expansion of the Universe and can\n",
            "therefore not represent the dark matter in a warped braneworld. We present\n",
            "results for the production of massless and KK gravitons for bouncing branes in\n",
            "five-dimensional anti de Sitter space. We find that for a realistic bounce the\n",
            "back reaction from the generated gravitons will be most likely relevant. This\n",
            "letter summarizes the main results and conclusions from numerical simulations\n",
            "which are presented in detail in a long paper [M.Ruser and R. Durrer, Phys.\n",
            "Rev. D 76, 104014 (2007), arXiv:0704.0790]\n",
            "\n",
            "----------------------------------------------\n",
            "Title: The Sloan Digital Sky Survey Quasar Catalog IV. Fifth Data Release\n",
            "Authors: Donald P. Schneider, Patrick B. Hall, Gordon T. Richards, Michael A.\n",
            "  Strauss, Daniel E. Vanden Berk, Scott F. Anderson, W.N. Brandt, Xiaohui Fan,\n",
            "  Sebastian Jester, Jim Gray, James E. Gunn, Mark U. SubbaRao, Anirudda R.\n",
            "  Thakar, Chris Stoughton, Alexander S. Szalay, Brian Yanny, Donald G. York,\n",
            "  Neta A. Bahcall, J. Barentine, Michael R. Blanton, Howard Brewington, J.\n",
            "  Brinkmann, Robert J. Brunner, Francisco J. Castander, Istvan Csabai, Joshua\n",
            "  A. Frieman, Masataka Fukugita, Michael Harvanek, David W. Hogg, Zeljko\n",
            "  Ivezic, Stephen M. Kent, S. J. Kleinman, G. R. Knapp, Richard G. Kron, Jurek\n",
            "  Krzesinski, Daniel C. Long, Robert H. Lupton, Atsuko Nitta, Jeffrey R. Pier,\n",
            "  David H. Saxe, Yue Shen, Stephanie A. Snedden, David H. Weinberg, and Jian Wu\n",
            "Categories: Astrophysics\n",
            "Doi: 10.1086/518474\n",
            "  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar\n",
            "Catalog. The catalog contains 77,429 objects; this is an increase of over\n",
            "30,000 entries since the previous edition. The catalog consists of the objects\n",
            "in the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0\n",
            "(in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7)\n",
            "have at least one emission line with FWHM larger than 1000 km/s, or have\n",
            "interesting/complex absorption features, are fainter than i=15.0, and have\n",
            "highly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The\n",
            "quasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the\n",
            "catalog includes 891 quasars at redshifts greater than four, of which 36 are at\n",
            "redshifts greater than five. Approximately half of the catalog quasars have i <\n",
            "19; nearly all have i < 21. For each object the catalog presents positions\n",
            "accurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz)\n",
            "CCD-based photometry with typical accuracy of 0.03 mag, and information on the\n",
            "morphology and selection method. The catalog also contains basic radio,\n",
            "near-infrared, and X-ray emission properties of the quasars, when available,\n",
            "from other large-area surveys. The calibrated digital spectra cover the\n",
            "wavelength region 3800--9200A at a spectral resolution of ~2000. The spectra\n",
            "can be retrieved from the public database using the information provided in the\n",
            "catalog. The average SDSS colors of quasars as a function of redshift, derived\n",
            "from the catalog entries, are presented in tabular form. Approximately 96% of\n",
            "the objects in the catalog were discovered by the SDSS.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Constraining the Dark Energy Equation of State with Cosmic Voids\n",
            "Authors: Jounghun Lee, Daeseong Park (Seoul Nat'l Univ.)\n",
            "Categories: Astrophysics\n",
            "Doi: 10.1088/0004-637X/696/1/L10\n",
            "  Our universe is observed to be accelerating due to the dominant dark energy\n",
            "with negative pressure. The dark energy equation of state (w) holds a key to\n",
            "understanding the ultimate fate of the universe. The cosmic voids behave like\n",
            "bubbles in the universe so that their shapes must be quite sensitive to the\n",
            "background cosmology. Assuming a flat universe and using the priors on the\n",
            "matter density parameter (Omega_m) and the dimensionless Hubble parameter (h),\n",
            "we demonstrate analytically that the ellipticity evolution of cosmic voids may\n",
            "be a sensitive probe of the dark energy equation of state. We also discuss the\n",
            "parameter degeneracy between w and Omega_m.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Extragalactic Radio Sources and the WMAP Cold Spot\n",
            "Authors: Lawrence Rudnick, Shea Brown, and Liliya R. Williams\n",
            "Categories: Astrophysics\n",
            "Doi: 10.1086/522222\n",
            "  We detect a dip of 20-45% in the surface brightness and number counts of NVSS\n",
            "sources smoothed to a few degrees at the location of the WMAP cold spot. The\n",
            "dip has structure on scales of approximately 1-10 degrees. Together with\n",
            "independent all-sky wavelet analyses, our results suggest that the dip in\n",
            "extragalactic brightness and number counts and the WMAP cold spot are\n",
            "physically related, i.e., that the coincidence is neither a statistical anomaly\n",
            "nor a WMAP foreground correction problem. If the cold spot does originate from\n",
            "structures at modest redshifts, as we suggest, then there is no remaining need\n",
            "for non-Gaussian processes at the last scattering surface of the CMB to explain\n",
            "the cold spot. The late integrated Sachs-Wolfe effect, already seen\n",
            "statistically for NVSS source counts, can now be seen to operate on a single\n",
            "region. To create the magnitude and angular size of the WMAP cold spot requires\n",
            "a ~140 Mpc radius completely empty void at z<=1 along this line of sight. This\n",
            "is far outside the current expectations of the concordance cosmology, and adds\n",
            "to the anomalies seen in the CMB.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: The Measure for the Multiverse and the Probability for Inflation\n",
            "Authors: Miao Li, Yi Wang\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1088/1475-7516/2007/06/012\n",
            "  We investigate the measure problem in the framework of inflationary\n",
            "cosmology. The measure of the history space is constructed and applied to\n",
            "inflation models. Using this measure, it is shown that the probability for the\n",
            "generalized single field slow roll inflation to last for $N$ e-folds is\n",
            "suppressed by a factor $\\exp(-3N)$, and the probability for the generalized\n",
            "$n$-field slow roll inflation is suppressed by a much larger factor\n",
            "$\\exp(-3nN)$. Some non-inflationary models such as the cyclic model do not\n",
            "suffer from this difficulty.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Did time begin? Will time end?\n",
            "Authors: Paul H. Frampton\n",
            "Categories: Astrophysics\n",
            "Doi: None\n",
            "  Did time begin at a Big Bang? Will the present expansion of the universe last\n",
            "for a finite or infinite time? These questions sound philosophical but are\n",
            "becoming, now in the twenty-first century, central to the scientific study of\n",
            "cosmology. The answers, which should become clarified in the next decade or\n",
            "two, could have profound implications for how we see our own role in the\n",
            "universe. Since the original publication of Stephen Hawking's {\\it A Brief\n",
            "History of Time} in 1988, the answers to these questions have progressed as a\n",
            "result of research by the community of active theoretical physicists including\n",
            "myself. To present the underlying ideas requires discussion of a wide range of\n",
            "topics in cosmology, especially the make up of the energy content of the\n",
            "universe. A brief summary of my conclusions, that of three different\n",
            "possibilities concerning the history and future of time, the least likely is\n",
            "the conventional wisdom (time began and will never end) and most likely is a\n",
            "cyclic model (time never begins or ends), is in the short final Chapter which\n",
            "could be read first. To understand the reasoning leading to my conclusions\n",
            "could encourage reading of my entire book. My hope in writing this, my first\n",
            "popular book, is that it will engender reflection about time. Many a\n",
            "non-scientist may already hold a philosophical opinion about whether time\n",
            "begins and ends. This book's aim is to present some recently discovered\n",
            "scientific facts which can focus the reader's consideration of the two short\n",
            "questions in my title.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Lattice refining loop quantum cosmology, anisotropic models and\n",
            "  stability\n",
            "Authors: Martin Bojowald, Daniel Cartin and Gaurav Khanna\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: 10.1103/PhysRevD.76.064018\n",
            "  A general class of loop quantizations for anisotropic models is introduced\n",
            "and discussed, which enhances loop quantum cosmology by relevant features seen\n",
            "in inhomogeneous situations. The main new effect is an underlying lattice which\n",
            "is being refined during dynamical changes of the volume. In general, this leads\n",
            "to a new feature of dynamical difference equations which may not have constant\n",
            "step-size, posing new mathematical problems. It is discussed how such models\n",
            "can be evaluated and what lattice refinements imply for semiclassical behavior.\n",
            "Two detailed examples illustrate that stability conditions can put strong\n",
            "constraints on suitable refinement models, even in the absence of a fundamental\n",
            "Hamiltonian which defines changes of the underlying lattice. Thus, a large\n",
            "class of consistency tests of loop quantum gravity becomes available. In this\n",
            "context, it will also be seen that quantum corrections due to inverse powers of\n",
            "metric components in a constraint are much larger than they appeared recently\n",
            "in more special treatments of isotropic, free scalar models where they were\n",
            "artificially suppressed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCM8IOiv4tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ae0180-fd50-4ac1-c35f-0fe248e22772"
      },
      "source": [
        "#Clusters with it's main element most similar to documents in retrieved\n",
        "sml_clusters = getClusters(sml, ctr_std, retrieved)\n",
        "for index in sml_clusters:\n",
        "  print(index)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "8\n",
            "13\n",
            "36\n",
            "47\n",
            "99\n",
            "109\n",
            "133\n",
            "135\n",
            "137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints information of the elements in one cluster\n",
        "print_info_lst(clusters_std[sml_clusters[1]], itemdata, physics_subc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkVwtZBTkB6l",
        "outputId": "354ebf2d-8cab-4143-ea12-3fffbdf3fb07"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "Title: Exact Solutions of Einstein-Yang-Mills Theory with Higher-Derivative\n",
            "  Coupling\n",
            "Authors: Hironobu Kihara, Muneto Nitta\n",
            "Categories: General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.085001\n",
            "  We construct a classical solution of an Einstein-Yang-Mills system with a\n",
            "fourth order term with respect to the field strength of the Yang-Mills field.\n",
            "The solution provides a spontaneous compactification proposed by Cremmer and\n",
            "Scherk; ten-dimensional space-time with a cosmological constant is compactified\n",
            "to the four-dimensional Minkowski space with a six-dimensional sphere S^6 on\n",
            "which an instanton solution exists. The radius of the sphere is not a modulus\n",
            "but is determined by the gauge coupling and the four-derivative coupling\n",
            "constants and the Newton's constant. We also construct a solution of\n",
            "ten-dimensional theory without a cosmological constant compactified to AdS_4 x\n",
            "S^6.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: ALMA as the ideal probe of the solar chromosphere\n",
            "Authors: M. A. Loukitcheva, S. K. Solanki and S. White\n",
            "Categories: Astrophysics\n",
            "Doi: 10.1007/s10509-007-9626-1\n",
            "  The very nature of the solar chromosphere, its structuring and dynamics,\n",
            "remains far from being properly understood, in spite of intensive research.\n",
            "Here we point out the potential of chromospheric observations at millimeter\n",
            "wavelengths to resolve this long-standing problem. Computations carried out\n",
            "with a sophisticated dynamic model of the solar chromosphere due to Carlsson\n",
            "and Stein demonstrate that millimeter emission is extremely sensitive to\n",
            "dynamic processes in the chromosphere and the appropriate wavelengths to look\n",
            "for dynamic signatures are in the range 0.8-5.0 mm. The model also suggests\n",
            "that high resolution observations at mm wavelengths, as will be provided by\n",
            "ALMA, will have the unique property of reacting to both the hot and the cool\n",
            "gas, and thus will have the potential of distinguishing between rival models of\n",
            "the solar atmosphere. Thus, initial results obtained from the observations of\n",
            "the quiet Sun at 3.5 mm with the BIMA array (resolution of 12 arcsec) reveal\n",
            "significant oscillations with amplitudes of 50-150 K and frequencies of 1.5-8\n",
            "mHz with a tendency toward short-period oscillations in internetwork and longer\n",
            "periods in network regions. However higher spatial resolution, such as that\n",
            "provided by ALMA, is required for a clean separation between the features\n",
            "within the solar atmosphere and for an adequate comparison with the output of\n",
            "the comprehensive dynamic simulations.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Why there is something rather than nothing (out of everything)?\n",
            "Authors: A.O.Barvinsky\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevLett.99.071301\n",
            "  The path integral over Euclidean geometries for the recently suggested\n",
            "density matrix of the Universe is shown to describe a microcanonical ensemble\n",
            "in quantum cosmology. This ensemble corresponds to a uniform (weight one)\n",
            "distribution in phase space of true physical variables, but in terms of the\n",
            "observable spacetime geometry it is peaked about complex saddle-points of the\n",
            "{\\em Lorentzian} path integral. They are represented by the recently obtained\n",
            "cosmological instantons limited to a bounded range of the cosmological\n",
            "constant. Inflationary cosmologies generated by these instantons at late stages\n",
            "of expansion undergo acceleration whose low-energy scale can be attained within\n",
            "the concept of dynamically evolving extra dimensions. Thus, together with the\n",
            "bounded range of the early cosmological constant, this cosmological ensemble\n",
            "suggests the mechanism of constraining the landscape of string vacua and,\n",
            "simultaneously, a possible solution to the dark energy problem in the form of\n",
            "the quasi-equilibrium decay of the microcanonical state of the Universe.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Solar System Constraints on Gauss-Bonnet Mediated Dark Energy\n",
            "Authors: Luca Amendola, Christos Charmousis and Stephen C. Davis\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1088/1475-7516/2007/10/004\n",
            "  Although the Gauss-Bonnet term is a topological invariant for general\n",
            "relativity, it couples naturally to a quintessence scalar field, modifying\n",
            "gravity at solar system scales. We determine the solar system constraints due\n",
            "to this term by evaluating the post-Newtonian metric for a distributional\n",
            "source. We find a mass dependent, 1/r^7 correction to the Newtonian potential,\n",
            "and also deviations from the Einstein gravity prediction for light-bending. We\n",
            "constrain the parameters of the theory using planetary orbits, the Cassini\n",
            "spacecraft data, and a laboratory test of Newton's law, always finding\n",
            "extremely tight bounds on the energy associated to the Gauss-Bonnet term. We\n",
            "discuss the relevance of these constraints to late-time cosmological\n",
            "acceleration.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Einstein vs Maxwell: Is gravitation a curvature of space, a field in\n",
            "  flat space, or both?\n",
            "Authors: Theo M. Nieuwenhuizen\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, Quantum Physics\n",
            "Doi: 10.1209/0295-5075/78/10010\n",
            "  Starting with a field theoretic approach in Minkowski space, the\n",
            "gravitational energy momentum tensor is derived from the Einstein equations in\n",
            "a straightforward manner. This allows to present them as {\\it acceleration\n",
            "tensor} = const. $\\times$ {\\it total energy momentum tensor}. For flat space\n",
            "cosmology the gravitational energy is negative and cancels the material energy.\n",
            "In the relativistic theory of gravitation a bimetric coupling between the\n",
            "Riemann and Minkowski metrics breaks general coordinate invariance. The case of\n",
            "a positive cosmological constant is considered. A singularity free version of\n",
            "the Schwarzschild black hole is solved analytically. In the interior the\n",
            "components of the metric tensor quickly die out, but do not change sign,\n",
            "leaving the role of time as usual. For cosmology the $\\Lambda$CDM model is\n",
            "covered, while there appears a form of inflation at early times. Here both the\n",
            "total energy and the zero point energy vanish.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: One-loop MHV Rules and Pure Yang-Mills\n",
            "Authors: Andreas Brandhuber, Bill Spence, Gabriele Travaglini, Konstantinos\n",
            "  Zoubos\n",
            "Categories: High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1088/1126-6708/2007/07/002\n",
            "  It has been known for some time that the standard MHV diagram formulation of\n",
            "perturbative Yang-Mills theory is incomplete, as it misses rational terms in\n",
            "one-loop scattering amplitudes of pure Yang-Mills. We propose that certain\n",
            "Lorentz violating counterterms, when expressed in the field variables which\n",
            "give rise to standard MHV vertices, produce precisely these missing terms.\n",
            "These counterterms appear when Yang-Mills is treated with a regulator,\n",
            "introduced by Thorn and collaborators, which arises in worldsheet formulations\n",
            "of Yang-Mills theory in the lightcone gauge. As an illustration of our\n",
            "proposal, we show that a simple one-loop, two-point counterterm is the\n",
            "generating function for the infinite sequence of one-loop, all-plus helicity\n",
            "amplitudes in pure Yang-Mills, in complete agreement with known expressions.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: The effect of a fifth large-scale space-time dimension on the\n",
            "  conservation of energy in a four dimensional Universe\n",
            "Authors: M.B. Gerrard and T.J. Sumner\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: None\n",
            "  The effect of introducing a fifth large-scale space-time dimension to the\n",
            "equations of orbital dynamics was analysed in an earlier paper by the authors.\n",
            "The results showed good agreement with the observed flat rotation curves of\n",
            "galaxies and the Pioneer Anomaly. This analysis did not require the\n",
            "modification of Newtonian dynamics, but rather only their restatement in a five\n",
            "dimensional framework. The same analysis derived a acceleration parameter ar,\n",
            "which plays an important role in the restated equations of orbital dynamics,\n",
            "and suggested a value for ar. In this companion paper, the principle of\n",
            "conservation of energy is restated within the same five-dimensional framework.\n",
            "The resulting analysis provides an alternative route to estimating the value of\n",
            "ar, without reference to the equations of orbital dynamics, and based solely on\n",
            "key cosmological constants and parameters, including the gravitational\n",
            "constant, G. The same analysis suggests that: (i) the inverse square law of\n",
            "gravity may itself be due to the conservation of energy at the boundary between\n",
            "a four-dimensional universe and a fifth large-scale space-time dimension; and\n",
            "(ii) there is a limiting case for the Tulley-Fisher relationship linking the\n",
            "speed of light to the mass of the Universe.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Generalized Nariai Solutions for Yang-type Monopoles\n",
            "Authors: Pablo Diaz, Antonio Segui\n",
            "Categories: General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.064033\n",
            "  A detailed study of the geometries that emerge by a gravitating generalized\n",
            "Yang monopole in even dimensions is carried out. In particular, those which\n",
            "present black hole and cosmological horizons. This two-horizon system is\n",
            "thermally unstable. The process of thermalization will drive both horizons to\n",
            "coalesce. This limit is what is profusely studied in this paper. It is shown\n",
            "that eventhough coordinate distance shrinks to zero, physical distance does\n",
            "not. So, there is some remaining space which geometry has been computed and\n",
            "identified as a generalized Nariai solution. The thermal properties of this new\n",
            "spacetime are then calculated. Topics, as the elliptical relation between radii\n",
            "of spheres in the geometry or a discussion about whether a mass-type term\n",
            "should be present in the line element or not, are also included.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Evolution of the Carter constant for inspirals into a black hole: effect\n",
            "  of the black hole quadrupole\n",
            "Authors: Eanna E. Flanagan and Tanja Hinderer\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: 10.1103/PhysRevD.75.124007 10.1103/PhysRevD.82.029901\n",
            "  10.1103/PhysRevD.82.129903\n",
            "  We analyze the effect of gravitational radiation reaction on generic orbits\n",
            "around a body with an axisymmetric mass quadrupole moment Q to linear order in\n",
            "Q, to the leading post-Newtonian order, and to linear order in the mass ratio.\n",
            "This system admits three constants of the motion in absence of radiation\n",
            "reaction: energy, angular momentum, and a third constant analogous to the\n",
            "Carter constant. We compute instantaneous and time-averaged rates of change of\n",
            "these three constants. For a point particle orbiting a black hole, Ryan has\n",
            "computed the leading order evolution of the orbit's Carter constant, which is\n",
            "linear in the spin. Our result, when combined with an interaction quadratic in\n",
            "the spin (the coupling of the black hole's spin to its own radiation reaction\n",
            "field), gives the next to leading order evolution. The effect of the\n",
            "quadrupole, like that of the linear spin term, is to circularize eccentric\n",
            "orbits and to drive the orbital plane towards antialignment with the symmetry\n",
            "axis. In addition we consider a system of two point masses where one body has a\n",
            "single mass multipole or current multipole. To linear order in the mass ratio,\n",
            "to linear order in the multipole, and to the leading post-Newtonian order, we\n",
            "show that there does not exist an analog of the Carter constant for such a\n",
            "system (except for the cases of spin and mass quadrupole). With mild additional\n",
            "assumptions, this result falsifies the conjecture that all vacuum, axisymmetric\n",
            "spacetimes posess a third constant of geodesic motion.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Exact Solutions of Einstein-Yang-Mills Theory with Higher-Derivative\n",
            "  Coupling\n",
            "Authors: Hironobu Kihara, Muneto Nitta\n",
            "Categories: General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.085001\n",
            "  We construct a classical solution of an Einstein-Yang-Mills system with a\n",
            "fourth order term with respect to the field strength of the Yang-Mills field.\n",
            "The solution provides a spontaneous compactification proposed by Cremmer and\n",
            "Scherk; ten-dimensional space-time with a cosmological constant is compactified\n",
            "to the four-dimensional Minkowski space with a six-dimensional sphere S^6 on\n",
            "which an instanton solution exists. The radius of the sphere is not a modulus\n",
            "but is determined by the gauge coupling and the four-derivative coupling\n",
            "constants and the Newton's constant. We also construct a solution of\n",
            "ten-dimensional theory without a cosmological constant compactified to AdS_4 x\n",
            "S^6.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Gravitational Duality Transformations on (A)dS4\n",
            "Authors: Robert G. Leigh, Anastasios C. Petkou\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1088/1126-6708/2007/11/079\n",
            "  We discuss the implementation of electric-magnetic duality transformations in\n",
            "four-dimensional gravity linearized around Minkowski or (A)dS4 backgrounds. In\n",
            "the presence of a cosmological constant duality generically modifies the\n",
            "Hamiltonian, nevertheless the bulk dynamics is unchanged. We pay particular\n",
            "attention to the boundary terms generated by the duality transformations and\n",
            "discuss their implications for holography.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Universe Without Singularities. A Group Approach to De Sitter Cosmology\n",
            "Authors: Ignazio Licata\n",
            "Categories: Physics\n",
            "Doi: None\n",
            "  In the last years the traditional scenario of Big Bang has been deeply\n",
            "modified by the study of the quantum features of the Universe evolution,\n",
            "proposing again the problem of using local physical laws on cosmic scale, with\n",
            "particular regard to the cosmological constant role. The group extention method\n",
            "shows that the De Sitter group univocally generalizes the Poincare group,\n",
            "formally justifies the cosmological constant use and suggests a new\n",
            "interpretation for Hartle-Hawking boundary conditions in Quantum Cosmology.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Cosmological Singularities and a Conjectured Gravity/Coset\n",
            "  Correspondence\n",
            "Authors: Thibault Damour\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: None\n",
            "  We review the recently discovered connection between the\n",
            "Belinsky-Khalatnikov-Lifshitz-like ``chaotic'' structure of generic\n",
            "cosmological singularities in eleven-dimensional supergravity and the ``last''\n",
            "hyperbolic Kac-Moody algebra E(10). This intriguing connection suggests the\n",
            "existence of a hidden ``correspondence'' between supergravity (or even\n",
            "M-theory) and null geodesic motion on the infinite-dimensional coset space\n",
            "K(E(10)). If true, this gravity/coset correspondence would offer a new view of\n",
            "the (quantum) fate of space (and matter) at cosmological singularities.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: LRS Bianchi Type-V Viscous Fluid Universe With a Time Dependent\n",
            "  Cosmological Term $\\Lambda$\n",
            "Authors: Anirudh Pradhan, J. P. Shahi and C. V. Singh\n",
            "Categories: General Relativity and Quantum Cosmology\n",
            "Doi: None\n",
            "  An LRS Bianchi type-V cosmological models representing a viscous fluid\n",
            "distribution with a time dependent cosmological term $\\Lambda$ is investigated.\n",
            "To get a determinate solution, the viscosity coefficient of bulk viscous fluid\n",
            "is assumed to be a power function of mass density. It turns out that the\n",
            "cosmological term $\\Lambda(t)$ is a decreasing function of time, which is\n",
            "consistent with recent observations of type Ia supernovae. Various physical and\n",
            "kinematic features of these models have also been explored.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Gauge-Higgs Unification and LHC/ILC\n",
            "Authors: Yutaka Hosotani\n",
            "Categories: High Energy Physics - Phenomenology\n",
            "Doi: 10.1142/9789812790750_0038\n",
            "  In the gauge-Higgs unification scenario the 4D Higgs field is identified with\n",
            "the zero mode of the extra-dimensional component of gauge potentials. The mass\n",
            "of the Higgs particle in the unification in the Randall-Sundrum warped\n",
            "spacetime is predicted to be in the range 100 GeV - 300 GeV. The WWZ gauge\n",
            "couplings remains almost universal as in the standard model, but substantial\n",
            "deviation results for the Higgs couplings. The WWH and ZZH couplings are\n",
            "suppressed by a factor \\cos \\theta_H from the values in the standard model,\n",
            "where \\theta_H is the Yang-Mills AB phase along the fifth dimension. These can\n",
            "be tested at LHC and ILC.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Cosmology from String Theory\n",
            "Authors: Luis Anchordoqui, Haim Goldberg, Satoshi Nawata, Carlos Nunez\n",
            "Categories: Astrophysics, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.126005\n",
            "  We explore the cosmological content of Salam-Sezgin six dimensional\n",
            "supergravity, and find a solution to the field equations in qualitative\n",
            "agreement with observation of distant supernovae, primordial nucleosynthesis\n",
            "abundances, and recent measurements of the cosmic microwave background. The\n",
            "carrier of the acceleration in the present de Sitter epoch is a quintessence\n",
            "field slowly rolling down its exponential potential. Intrinsic to this model is\n",
            "a second modulus which is automatically stabilized and acts as a source of cold\n",
            "dark matter with a mass proportional to an exponential function of the\n",
            "quintessence field (hence realizing VAMP models within a String context).\n",
            "However, any attempt to saturate the present cold dark matter component in this\n",
            "manner leads to unacceptable deviations from cosmological data -- a numerical\n",
            "study reveals that this source can account for up to about 7% of the total cold\n",
            "dark matter budget. We also show that (1) the model will support a de Sitter\n",
            "energy in agreement with observation at the expense of a miniscule breaking of\n",
            "supersymmetry in the compact space; (2) variations in the fine structure\n",
            "constant are controlled by the stabilized modulus and are negligible; (3)\n",
            "``fifth''forces are carried by the stabilized modulus and are short range; (4)\n",
            "the long time behavior of the model in four dimensions is that of a\n",
            "Robertson-Walker universe with a constant expansion rate (w = -1/3). Finally,\n",
            "we present a String theory background by lifting our six dimensional\n",
            "cosmological solution to ten dimensions.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Noncommutative Electromagnetism As A Large N Gauge Theory\n",
            "Authors: Hyun Seok Yang\n",
            "Categories: General Relativity and Quantum Cosmology, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1140/epjc/s10052-009-1117-9\n",
            "  We map noncommutative (NC) U(1) gauge theory on R^d_C X R^{2n}_{NC} to U(N ->\n",
            "\\infty) Yang-Mills theory on R^d_C, where R^d_C is a d-dimensional commutative\n",
            "spacetime while R^{2n}_{NC} is a 2n-dimensional NC space. The resulting U(N)\n",
            "Yang-Mills theory on R^d_C is equivalent to that obtained by the dimensional\n",
            "reduction of (d+2n)-dimensional U(N) Yang-Mills theory onto R^d_C. We show that\n",
            "the gauge-Higgs system (A_\\mu,\\Phi^a) in the U(N -> \\infty) Yang-Mills theory\n",
            "on R^d_C leads to an emergent geometry in the (d+2n)-dimensional spacetime\n",
            "whose metric was determined by Ward a long time ago. In particular, the\n",
            "10-dimensional gravity for d=4 and n=3 corresponds to the emergent geometry\n",
            "arising from the 4-dimensional N=4 vector multiplet in the AdS/CFT duality. We\n",
            "further elucidate the emergent gravity by showing that the gauge-Higgs system\n",
            "(A_\\mu,\\Phi^a) in half-BPS configurations describes self-dual Einstein gravity.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Glueball Masses in (2+1)-Dimensional Anisotropic Weakly-Coupled\n",
            "  Yang-Mills Theory\n",
            "Authors: Peter Orland\n",
            "Categories: Condensed Matter, High Energy Physics - Theory, Mathematical Physics\n",
            "Doi: 10.1103/PhysRevD.75.101702\n",
            "  The confinement problem has been solved in the anisotropic (2+1)-dimensional\n",
            "SU(N) Yang-Mills theory at weak coupling. In this paper, we find the low-lying\n",
            "spectrum for N=2. The lightest excitations are pairs of fundamental particles\n",
            "of the (1+1)-dimensional SU(2)XSU(2) principal chiral sigma model bound in a\n",
            "linear potential, with a specified matching condition where the particles\n",
            "overlap. This matching condition can be determined from the exactly-known\n",
            "S-matrix for the sigma model.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Late-time tails of a Yang-Mills field on Minkowski and Schwarzschild\n",
            "  backgrounds\n",
            "Authors: Piotr Bizo\\'n, Tadeusz Chmaj, Andrzej Rostworowski\n",
            "Categories: General Relativity and Quantum Cosmology, High Energy Physics - Theory\n",
            "Doi: 10.1088/0264-9381/24/13/F01\n",
            "  We study the late-time behavior of spherically symmetric solutions of the\n",
            "Yang-Mills equations on Minkowski and Schwarzschild backgrounds. Using\n",
            "nonlinear perturbation theory we show in both cases that solutions having\n",
            "smooth compactly supported initial data posses tails which decay as $t^{-4}$ at\n",
            "timelike infinity. Moreover, for small initial data on Minkowski background we\n",
            "derive the third-order formula for the amplitude of the tail and confirm\n",
            "numerically its accuracy.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Counting BPS operators in N=4 SYM\n",
            "Authors: F.A. Dolan\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1016/j.nuclphysb.2007.07.026\n",
            "  The free field partition function for a generic U(N) gauge theory, where the\n",
            "fundamental fields transform in the adjoint representation, is analysed in\n",
            "terms of symmetric polynomial techniques. It is shown by these means how this\n",
            "is related to the cycle polynomial for the symmetric group and how the large N\n",
            "result may be easily recovered. Higher order corrections for finite N are also\n",
            "discussed in terms of symmetric group characters. For finite N, the partition\n",
            "function involving a single bosonic fundamental field is recovered and explicit\n",
            "counting of multi-trace quarter BPS operators in free \\N=4 super Yang Mills\n",
            "discussed, including a general result for large N. The partition function for\n",
            "BPS operators in the chiral ring of \\N=4 super Yang Mills is analysed in terms\n",
            "of plane partitions. Asymptotic counting of BPS primary operators with\n",
            "differing R-symmetry charges is discussed in both free \\N=4 super Yang Mills\n",
            "and in the chiral ring. Also, general and explicit expressions are derived for\n",
            "SU(2) gauge theory partition functions, when the fundamental fields transform\n",
            "in the adjoint, for free field theory.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Bouncing Universe with Quintom Matter\n",
            "Authors: Yi-Fu Cai, Taotao Qiu, Yun-Song Piao, Mingzhe Li, Xinmin Zhang\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1088/1126-6708/2007/10/071\n",
            "  The bouncing universe provides a possible solution to the Big Bang\n",
            "singularity problem. In this paper we study the bouncing solution in the\n",
            "universe dominated by the Quintom matter with an equation of state (EoS)\n",
            "crossing the cosmological constant boundary. We will show explicitly the\n",
            "analytical and numerical bouncing solutions in three types of models for the\n",
            "Quintom matter with an phenomenological EoS, the two scalar fields and a scalar\n",
            "field with a modified Born-Infeld action.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Inflation, bifurcations of nonlinear curvature Lagrangians and dark\n",
            "  energy\n",
            "Authors: Eckehard W. Mielke, Fjodor V. Kusmartsev, Franz E. Schunck\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology\n",
            "Doi: 10.1142/9789812834300_0039\n",
            "  A possible equivalence of scalar dark matter, the inflaton, and modified\n",
            "gravity is analyzed. After a conformal mapping, the dependence of the effective\n",
            "Lagrangian on the curvature is not only singular but also bifurcates into\n",
            "several almost Einsteinian spaces, distinguished only by a different effective\n",
            "gravitational strength and cosmological constant. A swallow tail catastrophe in\n",
            "the bifurcation set indicates the possibility for the coexistence of different\n",
            "Einsteinian domains in our Universe. This `triple unification' may shed new\n",
            "light on the nature and large scale distribution not only of dark matter but\n",
            "also on `dark energy', regarded as an effective cosmological constant, and\n",
            "inflation.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Hall conductivity from dyonic black holes\n",
            "Authors: Sean A. Hartnoll and Pavel Kovtun\n",
            "Categories: High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.066001\n",
            "  A class of strongly interacting 2+1 dimensional conformal field theories in a\n",
            "transverse magnetic field can be studied using the AdS/CFT duality. We compute\n",
            "zero momentum hydrodynamic response functions of maximally supersymmetric 2+1\n",
            "dimensional SU(N) Yang-Mills theory at the conformal fixed point, in the large\n",
            "N limit. With background magnetic field B and electric charge density rho, the\n",
            "Hall conductivity is found to be rho/B. The result, anticipated on kinematic\n",
            "grounds in field theory, is obtained from perturbations of a four dimensional\n",
            "AdS black hole with both electric and magnetic charges.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Large Gauge Hierarchy in Gauge-Higgs Unification\n",
            "Authors: Kazunori Takenaga\n",
            "Categories: High Energy Physics - Phenomenology\n",
            "Doi: 10.1142/9789812790750_0040\n",
            "  We study a five dimensional nonsupersymmetric SU(3) gauge theory compactified\n",
            "on $M^4\\times S^1/Z_2$. The gauge hierarchy is discussed in the scenario of the\n",
            "gauge-Higgs unification. We present two models in which the large gauge\n",
            "hierarchy is realized, that is, the weak scale is naturally is obtained from an\n",
            "unique large scale such as a GUT and the Planck scale. We also study the Higgs\n",
            "mass in each model.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Non-minimal Wu-Yang wormhole\n",
            "Authors: Alexander B. Balakin, Sergey V. Sushkov, Alexei E. Zayats\n",
            "Categories: Astrophysics, General Relativity and Quantum Cosmology, High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.75.084042\n",
            "  We discuss exact solutions of three-parameter non-minimal Einstein-Yang-Mills\n",
            "model, which describe the wormholes of a new type. These wormholes are\n",
            "considered to be supported by SU(2)-symmetric Yang-Mills field, non-minimally\n",
            "coupled to gravity, the Wu-Yang ansatz for the gauge field being used. We\n",
            "distinguish between regular solutions, describing traversable non-minimal\n",
            "Wu-Yang wormholes, and black wormholes possessing one or two event horizons.\n",
            "The relation between the asymptotic mass of the regular traversable Wu-Yang\n",
            "wormhole and its throat radius is analysed.\n",
            "\n",
            "----------------------------------------------\n",
            "Title: Generalization of Einstein-Lovelock theory to higher order dilaton\n",
            "  gravity\n",
            "Authors: D. Konikowska, M. Olechowski\n",
            "Categories: High Energy Physics - Phenomenology, High Energy Physics - Theory\n",
            "Doi: 10.1103/PhysRevD.76.124020\n",
            "  A higher order theory of dilaton gravity is constructed as a generalization\n",
            "of the Einstein-Lovelock theory of pure gravity. Its Lagrangian contains terms\n",
            "with higher powers of the Riemann tensor and of the first two derivatives of\n",
            "the dilaton. Nevertheless, the resulting equations of motion are quasi-linear\n",
            "in the second derivatives of the metric and of the dilaton. This property is\n",
            "crucial for the existence of brane solutions in the thin wall limit. At each\n",
            "order in derivatives the contribution to the Lagrangian is unique up to an\n",
            "overall normalization. Relations between symmetries of this theory and the\n",
            "O(d,d) symmetry of the string-inspired models are discussed.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}